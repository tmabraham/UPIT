# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/02_data.unpaired.ipynb.

# %% auto 0
__all__ = ['RandPair', 'PILImageA', 'PILImageB', 'TensorImageA', 'TensorImageB', 'ToTensorA', 'ToTensorB', 'change_type_of_tfm',
           'get_dls', 'convert_func', 'create_image', 'get_dls_from_hf']

# %% ../../nbs/02_data.unpaired.ipynb 2
import fastcore
import inspect
from fastai.vision.all import *
from fastai.basics import *
from typing import List
from fastai.vision.gan import *
from datasets import load_dataset

# %% ../../nbs/02_data.unpaired.ipynb 15
class RandPair(Transform):
    "Returns a random image from domain B, resulting in a random pair of images from domain A and B."
    def __init__(self,itemsB): self.itemsB = itemsB
    def encodes(self,i): return random.choice(self.itemsB)

# %% ../../nbs/02_data.unpaired.ipynb 27
class PILImageA(PILImage): pass
class PILImageB(PILImage): pass
class TensorImageA(TensorImage): pass
class TensorImageB(TensorImage): pass

# %% ../../nbs/02_data.unpaired.ipynb 28
class ToTensorA(Transform):
    "Convert item to TensorImageA"
    order = 5
    def encodes(self, o:PILImageA): return TensorImageA(image2tensor(o))


class ToTensorB(Transform):
    "Convert item to TensorImageB"
    order = 5
    def encodes(self, o:PILImageB): return TensorImageB(image2tensor(o))

# %% ../../nbs/02_data.unpaired.ipynb 29
def change_type_of_tfm(tfm, old_type, new_type):
    assert old_type in new_type.mro() # make sure it's a subclass of the old type
    NewTfm = get_class(type(tfm).__name__+'_for_'+new_type.__name__,sup=type(tfm)) # create new transform that subclasses the original
    new_tfm = NewTfm() # initialize
    new_tfm.__dict__ = tfm.__dict__.copy() # copy everything over
    new_tfm.encodes.bases = L() # bases set to empty
    new_tfm.decodes.bases = L() # bases set to empty
    t_encodes = fastcore.dispatch._TypeDict() # create a _TypeDict for the encode funcs
    new_tfm.encodes.funcs = fastcore.dispatch._TypeDict() # create a _TypeDict for the encode funcs
    new_tfm.encodes.funcs.add(new_type, t_encodes) # add the new type
    if type(tfm).encodes.funcs.d.get(old_type) is not None: t_encodes.add(object, type(tfm).encodes.funcs.d.get(old_type).d.get(object)) # add the function
    t_decodes = fastcore.dispatch._TypeDict() # create a _TypeDict for the decode funcs
    new_tfm.decodes.funcs = fastcore.dispatch._TypeDict() # create a _TypeDict for the decode funcs
    new_tfm.decodes.funcs.add(new_type, t_decodes) # add the new type
    if type(tfm).decodes.funcs.d.get(old_type) is not None: t_decodes.add(object, type(tfm).decodes.funcs.d.get(old_type).d.get(object)) # add the function
    return new_tfm

# %% ../../nbs/02_data.unpaired.ipynb 36
def get_dls(pathA, pathB, num_A=None, num_B=None, load_size=512, crop_size=256, item_tfms=None, batch_tfms=None, bs=4, num_workers=2, normalize=False):
    """
    Given image files from two domains (`pathA`, `pathB`), create `DataLoaders` object.
    Loading and randomly cropped sizes of `load_size` and `crop_size` are set to defaults of 512 and 256.
    Batch size is specified by `bs` (default=4).
    """
    filesA = get_image_files(pathA)
    filesB = get_image_files(pathB)
    filesA = filesA[:min(ifnone(num_A, len(filesA)),len(filesA))]
    filesB = filesB[:min(ifnone(num_B, len(filesB)),len(filesB))]

    if item_tfms is None: item_tfms = [Resize(load_size), RandomCrop(crop_size)]
    if type(item_tfms)==dict:
        item_tfms = [Resize(load_size), RandomCrop(crop_size)] + [change_type_of_tfm(tfm, TensorImage, TensorImageA) for tfm in L(item_tfms.get(TensorImageA,[]))] \
        + [change_type_of_tfm(tfm, TensorImage, TensorImageB) for tfm in L(item_tfms.get(TensorImageB,[]))]
    
    dsets = Datasets(filesA, tfms=[[PILImageA.create, ToTensorA, *item_tfms],
                                   [RandPair(filesB),PILImageB.create, ToTensorB, *item_tfms]], splits=None)
    
    _batch_tfms = [IntToFloatTensor]
    
    new_batch_tfms = []
    
    if batch_tfms is None:
        if normalize == True:
            x_A = IntToFloatTensor()(torch.cat([torch.unsqueeze(i[0],0) for i in dsets]))
            meanA,stdA = x_A.mean((0,2,3), keepdim=True),x_A.std((0,2,3), keepdim=True)+1e-7
            x_B = IntToFloatTensor()(torch.cat([torch.unsqueeze(i[1],0) for i in dsets]))
            meanB,stdB = x_B.mean((0,2,3), keepdim=True),x_B.std((0,2,3), keepdim=True)+1e-7  
            new_batch_tfms += [change_type_of_tfm(Normalize.from_stats(mean=meanA,std=stdA),TensorImage,TensorImageA), 
                               change_type_of_tfm(Normalize.from_stats(mean=meanB,std=stdB),TensorImage,TensorImageB)]
        
        else: new_batch_tfms.append(Normalize.from_stats(mean=0.5, std=0.5))
            
        new_batch_tfms.append(FlipItem(p=0.5))
        
    if type(batch_tfms)==dict:
        new_batch_tfms += [change_type_of_tfm(tfm, TensorImage, TensorImageA) for tfm in L(batch_tfms.get(TensorImageA,[]))]
        new_batch_tfms += [change_type_of_tfm(tfm, TensorImage, TensorImageB) for tfm in L(batch_tfms.get(TensorImageB,[]))]
    _batch_tfms = _batch_tfms + new_batch_tfms

    dls = dsets.dataloaders(bs=bs, num_workers=num_workers, after_batch=_batch_tfms)

    return dls

# %% ../../nbs/02_data.unpaired.ipynb 64
def convert_func(x): return x.convert(mode='RGB')
def create_image(x, image_type): 
    if image_type == 'A': return PILImageA(x)
    if image_type == 'B': return PILImageB(x)


def get_dls_from_hf(dataset_name, fieldA='imageA', fieldB='imageB', num_A=None, num_B=None, load_size=512, crop_size=256, item_tfms=None, batch_tfms=None, bs=4, num_workers=2, normalize=False):
    """
    Given a name of a dataset available on the HuggingFace Hub, create `DataLoaders` object. 
    Field names given in `fieldA` and `fieldB` arguments.
    Loading and randomly cropped sizes of `load_size` and `crop_size` are set to defaults of 512 and 256.
    Batch size is specified by `bs` (default=4).
    """
    
    dataset = load_dataset(dataset_name)
    imagesA = dataset['train'][fieldA]
    imagesB = dataset['train'][fieldB]
    
    imagesA = imagesA[:min(ifnone(num_A, len(imagesA)),len(imagesA))]
    imagesB = imagesB[:min(ifnone(num_B, len(imagesB)),len(imagesB))]

    if item_tfms is None: item_tfms = [Resize(load_size), RandomCrop(crop_size)]
    if type(item_tfms)==dict:
        item_tfms = [Resize(load_size), RandomCrop(crop_size)] + [change_type_of_tfm(tfm, TensorImage, TensorImageA) for tfm in L(item_tfms.get(TensorImageA,[]))] \
        + [change_type_of_tfm(tfm, TensorImage, TensorImageB) for tfm in L(item_tfms.get(TensorImageB,[]))]
    
    dsets = Datasets(imagesA, tfms=[[np.asarray, Image.fromarray, convert_func, partial(create_image, image_type='A'), ToTensorA, *item_tfms], #np.asarray included as a hack to deal with JpegImageFile
                                   [RandPair(imagesB), np.asarray, Image.fromarray, convert_func, partial(create_image, image_type='B'), ToTensorB, *item_tfms]], splits=None) 

    _batch_tfms = [IntToFloatTensor]
    
    new_batch_tfms = []
    
    if batch_tfms is None:
        if normalize == True:
            x_A = IntToFloatTensor()(torch.cat([torch.unsqueeze(i[0],0) for i in dsets]))
            meanA,stdA = x_A.mean((0,2,3), keepdim=True),x_A.std((0,2,3), keepdim=True)+1e-7
            x_B = IntToFloatTensor()(torch.cat([torch.unsqueeze(i[1],0) for i in dsets]))
            meanB,stdB = x_B.mean((0,2,3), keepdim=True),x_B.std((0,2,3), keepdim=True)+1e-7  
            new_batch_tfms += [change_type_of_tfm(Normalize.from_stats(mean=meanA,std=stdA),TensorImage,TensorImageA), 
                               change_type_of_tfm(Normalize.from_stats(mean=meanB,std=stdB),TensorImage,TensorImageB)]
        
        else: new_batch_tfms.append(Normalize.from_stats(mean=0.5, std=0.5))
            
        new_batch_tfms.append(FlipItem(p=0.5))
        
    if type(batch_tfms)==dict:
        new_batch_tfms += [change_type_of_tfm(tfm, TensorImage, TensorImageA) for tfm in L(batch_tfms.get(TensorImageA,[]))]
        new_batch_tfms += [change_type_of_tfm(tfm, TensorImage, TensorImageB) for tfm in L(batch_tfms.get(TensorImageB,[]))]
    _batch_tfms = _batch_tfms + new_batch_tfms

    dls = dsets.dataloaders(bs=bs, num_workers=num_workers, after_batch=_batch_tfms)

    return dls
