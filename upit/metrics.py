# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/05_metrics.ipynb.

# %% auto 0
__all__ = ['InceptionV3', 'FrechetInceptionDistance']

# %% ../nbs/05_metrics.ipynb 2
from fastai.vision.all import *
from fastai.basics import *
from typing import List
from fastai.vision.gan import *
from .models.cyclegan import *
from .data.unpaired import *
from .train.cyclegan import *
from torchvision import models
from scipy import linalg

# %% ../nbs/05_metrics.ipynb 7
class InceptionV3(nn.Module):
    def __init__(self):
        super().__init__()
        inception = models.inception_v3(pretrained=True)
        self.block1 = nn.Sequential(
            inception.Conv2d_1a_3x3, inception.Conv2d_2a_3x3,
            inception.Conv2d_2b_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2))
        self.block2 = nn.Sequential(
            inception.Conv2d_3b_1x1, inception.Conv2d_4a_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2))
        self.block3 = nn.Sequential(
            inception.Mixed_5b, inception.Mixed_5c,
            inception.Mixed_5d, inception.Mixed_6a,
            inception.Mixed_6b, inception.Mixed_6c,
            inception.Mixed_6d, inception.Mixed_6e)
        self.block4 = nn.Sequential(
            inception.Mixed_7a, inception.Mixed_7b,
            inception.Mixed_7c,
            nn.AdaptiveAvgPool2d(output_size=(1, 1)))

    def forward(self, x):
        x = self.block1(x)
        x = self.block2(x)
        x = self.block3(x)
        x = self.block4(x)
        return x.view(x.size(0), -1)

# %% ../nbs/05_metrics.ipynb 8
class FrechetInceptionDistance(Metric):
    def __init__(self, model=None, device='cuda', yb_idx=0, pred_idx=1):
        store_attr()
        self.model = model
        if self.model is None: self.model = self.get_inception_model()
        self.stats_pred = []
        self.stats_targ = []


    @staticmethod
    def get_inception_model(): return InceptionV3()

    @staticmethod
    def calc_activations_for_batch(batch, model, device=None):

        model = model.to(device)
        batch = batch.to(device)
        with torch.no_grad(): pred = model(batch)

        pred = pred.cpu().numpy()

        model = model.cpu()
        return pred

    @staticmethod
    def calculate_activation_statistics(activations):
        mu = np.mean(activations,axis=0)
        sigma = np.cov(activations, rowvar=False)
        return mu, sigma

    @staticmethod
    def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):
        mu1 = np.atleast_1d(mu1)
        mu2 = np.atleast_1d(mu2)

        sigma1 = np.atleast_2d(sigma1)
        sigma2 = np.atleast_2d(sigma2)

        assert mu1.shape == mu2.shape, 'Training and test mean vectors have different lengths'
        assert sigma1.shape == sigma2.shape, 'Training and test covariances have different dimensions'

        diff = mu1 - mu2

        # Product might be almost singular
        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)
        if not np.isfinite(covmean).all():
            msg = ('fid calculation produces singular product; '
                   'adding %s to diagonal of cov estimates') % eps
            print(msg)
            offset = np.eye(sigma1.shape[0]) * eps
            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))

        # Numerical error might give slight imaginary component
        if np.iscomplexobj(covmean):
            if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):
                m = np.max(np.abs(covmean.imag))
                raise ValueError('Imaginary component {}'.format(m))
            covmean = covmean.real

        tr_covmean = np.trace(covmean)

        return (diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean)


    def accumulate(self, learn):
        self.stats_pred.append(self.calc_activations_for_batch(learn.pred[self.pred_idx], self.model, self.device))
        self.stats_targ.append(self.calc_activations_for_batch(learn.yb[self.yb_idx], self.model, self.device))


    @property
    def value(self):
        stats_pred_arr = np.concatenate(self.stats_pred,axis=0)
        stats_targ_arr = np.concatenate(self.stats_targ,axis=0)
        mu1, sigma1 = self.calculate_activation_statistics(stats_pred_arr)
        mu2, sigma2 = self.calculate_activation_statistics(stats_targ_arr)
        return self.calculate_frechet_distance(mu1, sigma1, mu2, sigma2)

    def reset(self):
        self.stats_pred = []
        self.stats_targ = []
