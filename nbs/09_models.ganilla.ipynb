{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANILLA model\n",
    "\n",
    "> Defines the GANILLA model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.ganilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from fastai.basics import *\n",
    "from typing import List\n",
    "from fastai.vision.gan import *\n",
    "from upit.models.cyclegan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the generator that was introduced in the [GANILLA paper](https://arxiv.org/abs/1703.10593)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BasicBlock_Ganilla(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, use_dropout, stride=1):\n",
    "        super(BasicBlock_Ganilla, self).__init__()\n",
    "        self.rp1 = nn.ReflectionPad2d(1)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=0, bias=False)\n",
    "        self.bn1 = nn.InstanceNorm2d(planes)\n",
    "        self.use_dropout = use_dropout\n",
    "        if use_dropout:\n",
    "            self.dropout = nn.Dropout(use_dropout)\n",
    "        self.rp2 = nn.ReflectionPad2d(1)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.InstanceNorm2d(planes)\n",
    "        self.out_planes = planes\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.InstanceNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "            self.final_conv = nn.Sequential(\n",
    "                nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(self.expansion * planes * 2, self.expansion * planes, kernel_size=3, stride=1,\n",
    "                                        padding=0, bias=False),\n",
    "                nn.InstanceNorm2d(self.expansion * planes)\n",
    "            )\n",
    "        else:\n",
    "            self.final_conv = nn.Sequential(\n",
    "                nn.ReflectionPad2d(1),\n",
    "                nn.Conv2d(planes*2, planes, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "                nn.InstanceNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(self.rp1(x))))\n",
    "        if self.use_dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(self.rp2(out)))\n",
    "        inputt = self.shortcut(x)\n",
    "        catted = torch.cat((out, inputt), 1)\n",
    "        out = self.final_conv(catted)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PyramidFeatures(nn.Module):\n",
    "    def __init__(self, C2_size, C3_size, C4_size, C5_size, fpn_weights, feature_size=128):\n",
    "        super(PyramidFeatures, self).__init__()\n",
    "\n",
    "        self.sum_weights = fpn_weights #[1.0, 0.5, 0.5, 0.5]\n",
    "\n",
    "        # upsample C5 to get P5 from the FPN paper\n",
    "        self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        self.P5_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        #self.rp1 = nn.ReflectionPad2d(1)\n",
    "        #self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "        # add P5 elementwise to C4\n",
    "        self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        self.P4_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        #self.rp2 = nn.ReflectionPad2d(1)\n",
    "        #self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "        # add P4 elementwise to C3\n",
    "        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        self.P3_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        #self.rp3 = nn.ReflectionPad2d(1)\n",
    "        #self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "        self.P2_1 = nn.Conv2d(C2_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        self.P2_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.rp4 = nn.ReflectionPad2d(1)\n",
    "        self.P2_2 = nn.Conv2d(int(feature_size), int(feature_size/2), kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "        #self.P1_1 = nn.Conv2d(feature_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        #self.P1_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        #self.rp5 = nn.ReflectionPad2d(1)\n",
    "        #self.P1_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        C2, C3, C4, C5 = inputs\n",
    "\n",
    "        i = 0\n",
    "        P5_x = self.P5_1(C5) * self.sum_weights[i]\n",
    "        P5_upsampled_x = self.P5_upsampled(P5_x)\n",
    "        #P5_x = self.rp1(P5_x)\n",
    "        # #P5_x = self.P5_2(P5_x)\n",
    "        i += 1\n",
    "        P4_x = self.P4_1(C4) * self.sum_weights[i]\n",
    "        P4_x = P5_upsampled_x + P4_x\n",
    "        P4_upsampled_x = self.P4_upsampled(P4_x)\n",
    "        #P4_x = self.rp2(P4_x)\n",
    "        # #P4_x = self.P4_2(P4_x)\n",
    "        i += 1\n",
    "        P3_x = self.P3_1(C3) * self.sum_weights[i]\n",
    "        P3_x = P3_x + P4_upsampled_x\n",
    "        P3_upsampled_x = self.P3_upsampled(P3_x)\n",
    "        #P3_x = self.rp3(P3_x)\n",
    "        #P3_x = self.P3_2(P3_x)\n",
    "        i += 1\n",
    "        P2_x = self.P2_1(C2) * self.sum_weights[i]\n",
    "        P2_x = P2_x * self.sum_weights[2] + P3_upsampled_x\n",
    "        P2_upsampled_x = self.P2_upsampled(P2_x)\n",
    "        P2_x = self.rp4(P2_upsampled_x)\n",
    "        P2_x = self.P2_2(P2_x)\n",
    "\n",
    "        return P2_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf, use_dropout, fpn_weights, block, layers):\n",
    "        self.inplanes = ngf\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        # first conv\n",
    "        self.pad1 = nn.ReflectionPad2d(input_nc)\n",
    "        self.conv1 = nn.Conv2d(input_nc, ngf, kernel_size=7, stride=1, padding=0, bias=True)\n",
    "        self.in1 = nn.InstanceNorm2d(ngf)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pad2 = nn.ReflectionPad2d(1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "\n",
    "        # Output layer\n",
    "        self.pad3 = nn.ReflectionPad2d(output_nc)\n",
    "        self.conv2 = nn.Conv2d(64, output_nc, 7)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "        if block == BasicBlock_Ganilla:\n",
    "            # residuals\n",
    "            self.layer1 = self._make_layer_ganilla(block, 64, layers[0], use_dropout, stride=1)\n",
    "            self.layer2 = self._make_layer_ganilla(block, 128, layers[1], use_dropout, stride=2)\n",
    "            self.layer3 = self._make_layer_ganilla(block, 128, layers[2], use_dropout, stride=2)\n",
    "            self.layer4 = self._make_layer_ganilla(block, 256, layers[3], use_dropout, stride=2)\n",
    "\n",
    "            fpn_sizes = [self.layer1[layers[0] - 1].conv2.out_channels,\n",
    "                         self.layer2[layers[1] - 1].conv2.out_channels,\n",
    "                         self.layer3[layers[2] - 1].conv2.out_channels,\n",
    "                         self.layer4[layers[3] - 1].conv2.out_channels]\n",
    "\n",
    "        else:\n",
    "            print(\"This block type is not supported\")\n",
    "            sys.exit()\n",
    "\n",
    "        self.fpn = PyramidFeatures(fpn_sizes[0], fpn_sizes[1], fpn_sizes[2], fpn_sizes[3], fpn_weights)\n",
    "\n",
    "    \n",
    "    def _make_layer_ganilla(self, block, planes, blocks, use_dropout, stride=1):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inplanes, planes, use_dropout, stride))\n",
    "            self.inplanes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        '''Freeze BatchNorm layers.'''\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.BatchNorm2d):\n",
    "                layer.eval()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        img_batch = inputs\n",
    "\n",
    "        x = self.pad1(img_batch)\n",
    "        x = self.conv1(x)\n",
    "        x = self.in1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pad2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "\n",
    "        out = self.fpn([x1, x2, x3, x4]) # use all resnet layers\n",
    "\n",
    "        out = self.pad3(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                torch.nn.init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                torch.nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                torch.nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                torch.nn.init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, gain)\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    net.apply(init_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ganilla_generator(input_nc, output_nc, ngf, drop, fpn_weights=[1.0, 1.0, 1.0, 1.0], init_type='normal', gain=0.02, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 GANILLA generator.\"\"\"\n",
    "    model = ResNet(input_nc, output_nc, ngf, drop, fpn_weights, BasicBlock_Ganilla, [2, 2, 2, 2],  **kwargs)\n",
    "    init_weights(model,init_type='normal', gain=gain)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test for a few things:\n",
    "1. The generator can indeed be initialized correctly\n",
    "2. A random image can be passed into the model successfully with the correct size output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a random batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ganilla_generator(3,3,64,0.5)\n",
    "with torch.no_grad():\n",
    "    out1 = m(img1)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group two discriminators and two generators in a single model, then a `Callback` (defined in `02_cyclegan_training.ipynb`) will take care of training them properly. The discriminator and training loop is the same as CycleGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GANILLA(nn.Module):\n",
    "    \"\"\"\n",
    "    GANILLA model. \\n\n",
    "    When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
    "    Also outputs identity images after passing the images into generators that outputs its domain type (needed for identity loss).\n",
    "\n",
    "    Attributes: \\n\n",
    "    `G_A` (`nn.Module`): takes real input B and generates fake input A \\n\n",
    "    `G_B` (`nn.Module`): takes real input A and generates fake input B \\n\n",
    "    `D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \\n\n",
    "    `D_B` (`nn.Module`): trained to make the difference between real input B and fake input B \\n\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in:int=3, ch_out:int=3, n_features:int=64, disc_layers:int=3, lsgan:bool=True, \n",
    "                 drop:float=0., norm_layer:nn.Module=None, fpn_weights:list=[1.0, 1.0, 1.0, 1.0], init_type:str='normal', gain:float=0.02,**kwargs):\n",
    "        \"\"\"\n",
    "        Constructor for GANILLA model.\n",
    "        \n",
    "        Arguments: \\n\n",
    "        `ch_in` (`int`): Number of input channels (default=3) \\n\n",
    "        `ch_out` (`int`): Number of output channels (default=3) \\n\n",
    "        `n_features` (`int`): Number of input features (default=64) \\n\n",
    "        `disc_layers` (`int`): Number of discriminator layers (default=3) \\n\n",
    "        `lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \\n\n",
    "        `drop` (`float`): Level of dropout (default=0) \\n\n",
    "        `norm_layer` (`nn.Module`): Type of normalization layer to use in the discriminator (default=None)\n",
    "        `fpn_weights` (`list`): Weights for feature pyramid network (default=[1.0, 1.0, 1.0, 1.0]) \\n\n",
    "        `init_type` (`str`): Type of initialization (default='normal') \\n\n",
    "        `gain` (`float`): Gain for initialization (default=0.02)\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        #G_A: takes real input B and generates fake input A\n",
    "        #G_B: takes real input A and generates fake input B\n",
    "        #D_A: trained to make the difference between real input A and fake input A\n",
    "        #D_B: trained to make the difference between real input B and fake input B\n",
    "        self.D_A = discriminator(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n",
    "        self.D_B = discriminator(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n",
    "        self.G_A = ganilla_generator(ch_in, ch_out, n_features, drop, fpn_weights, init_type, gain, **kwargs)\n",
    "        self.G_B = ganilla_generator(ch_in, ch_out, n_features, drop, fpn_weights, init_type, gain, **kwargs)\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function for CycleGAN model. The input is a tuple of a batch of real images from both domains A and B.\"\"\"\n",
    "        real_A, real_B = input\n",
    "        fake_A, fake_B = self.G_A(real_B), self.G_B(real_A)\n",
    "        idt_A, idt_B = self.G_A(real_A), self.G_B(real_B) #Needed for the identity loss during training.\n",
    "        return [fake_A, fake_B, idt_A, idt_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"GANILLA\" class=\"doc_header\"><code>class</code> <code>GANILLA</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>GANILLA</code>(**`ch_in`**:`int`=*`3`*, **`ch_out`**:`int`=*`3`*, **`n_features`**:`int`=*`64`*, **`disc_layers`**:`int`=*`3`*, **`lsgan`**:`bool`=*`True`*, **`drop`**:`float`=*`0.0`*, **`norm_layer`**:`Module`=*`None`*, **`fpn_weights`**:`list`=*`[1.0, 1.0, 1.0, 1.0]`*, **`init_type`**:`str`=*`'normal'`*, **`gain`**:`float`=*`0.02`*, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "GANILLA model. \n",
       "\n",
       "When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
       "Also outputs identity images after passing the images into generators that outputs its domain type (needed for identity loss).\n",
       "\n",
       "Attributes: \n",
       "\n",
       "`G_A` (`nn.Module`): takes real input B and generates fake input A \n",
       "\n",
       "`G_B` (`nn.Module`): takes real input A and generates fake input B \n",
       "\n",
       "`D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \n",
       "\n",
       "`D_B` (`nn.Module`): trained to make the difference between real input B and fake input B "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GANILLA,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GANILLA.__init__\" class=\"doc_header\"><code>GANILLA.__init__</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GANILLA.__init__</code>(**`ch_in`**:`int`=*`3`*, **`ch_out`**:`int`=*`3`*, **`n_features`**:`int`=*`64`*, **`disc_layers`**:`int`=*`3`*, **`lsgan`**:`bool`=*`True`*, **`drop`**:`float`=*`0.0`*, **`norm_layer`**:`Module`=*`None`*, **`fpn_weights`**:`list`=*`[1.0, 1.0, 1.0, 1.0]`*, **`init_type`**:`str`=*`'normal'`*, **`gain`**:`float`=*`0.02`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Constructor for GANILLA model.\n",
       "\n",
       "Arguments: \n",
       "\n",
       "`ch_in` (`int`): Number of input channels (default=3) \n",
       "\n",
       "`ch_out` (`int`): Number of output channels (default=3) \n",
       "\n",
       "`n_features` (`int`): Number of input features (default=64) \n",
       "\n",
       "`disc_layers` (`int`): Number of discriminator layers (default=3) \n",
       "\n",
       "`lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \n",
       "\n",
       "`drop` (`float`): Level of dropout (default=0) \n",
       "\n",
       "`norm_layer` (`nn.Module`): Type of normalization layer to use in the discriminator (default=None)\n",
       "`fpn_weights` (`list`): Weights for feature pyramid network (default=[1.0, 1.0, 1.0, 1.0]) \n",
       "\n",
       "`init_type` (`str`): Type of initialization (default='normal') \n",
       "\n",
       "`gain` (`float`): Gain for initialization (default=0.02)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GANILLA.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GANILLA.forward\" class=\"doc_header\"><code>GANILLA.forward</code><a href=\"__main__.py#L43\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GANILLA.forward</code>(**`input`**)\n",
       "\n",
       "Forward function for CycleGAN model. The input is a tuple of a batch of real images from both domains A and B."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GANILLA.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model tests\n",
    "\n",
    "Again, let's check that the model can be called sucsessfully and outputs the correct shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganilla_model = GANILLA()\n",
    "img1 = torch.randn(4,3,256,256)\n",
    "img2 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 3.26 s, total: 21.6 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad(): ganilla_output = ganilla_model((img1,img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(ganilla_output),4)\n",
    "for output_batch in ganilla_output:\n",
    "    test_eq(output_batch.shape,img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_models.cyclegan.ipynb.\n",
      "Converted 01b_models.junyanz.ipynb.\n",
      "Converted 02_data.unpaired.ipynb.\n",
      "Converted 03_train.cyclegan.ipynb.\n",
      "Converted 04_inference.cyclegan.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_tracking.wandb.ipynb.\n",
      "Converted 07_models.dualgan.ipynb.\n",
      "Converted 08_train.dualgan.ipynb.\n",
      "Converted 09_models.ganilla.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
