{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DualGAN model\n",
    "\n",
    "> Defines the DualGAN model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.dualgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from fastai.basics import *\n",
    "from typing import List\n",
    "from fastai.vision.gan import *\n",
    "from upit.models.cyclegan import *\n",
    "from huggingface_hub import PyTorchModelHubMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the models that were introduced in the [DualGAN paper](https://arxiv.org/abs/1704.02510). The original implementation is [here](https://github.com/duxingren14/DualGAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNetDown(nn.Module):\n",
    "    \"Contracting layers of the Unet used in DualGAN\"\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, 4, stride=2, padding=1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size, affine=True))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    \"Expanding layers of the Unet used in DualGAN\"\n",
    "    def __init__(self, in_size, out_size, dropout=0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_size, out_size, 4, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(out_size, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"UNetDown\" class=\"doc_header\"><code>class</code> <code>UNetDown</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>UNetDown</code>(**`in_size`**, **`out_size`**, **`normalize`**=*`True`*, **`dropout`**=*`0.0`*) :: `Module`\n",
       "\n",
       "Contracting layers of the Unet used in DualGAN"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(UNetDown,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DualGANGenerator(nn.Module):\n",
    "    \"Generator model for the DualGAN\"\n",
    "    def __init__(self, channels=3):\n",
    "        super(DualGANGenerator, self).__init__()\n",
    "\n",
    "        self.down1 = UNetDown(channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.5, normalize=False)\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up4 = UNetUp(1024, 256)\n",
    "        self.up5 = UNetUp(512, 128)\n",
    "        self.up6 = UNetUp(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(nn.ConvTranspose2d(128, channels, 4, stride=2, padding=1), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        u1 = self.up1(d7, d6)\n",
    "        u2 = self.up2(u1, d5)\n",
    "        u3 = self.up3(u2, d4)\n",
    "        u4 = self.up4(u3, d3)\n",
    "        u5 = self.up5(u4, d2)\n",
    "        u6 = self.up6(u5, d1)\n",
    "\n",
    "        return self.final(u6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"DualGANGenerator\" class=\"doc_header\"><code>class</code> <code>DualGANGenerator</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>DualGANGenerator</code>(**`channels`**=*`3`*) :: `Module`\n",
       "\n",
       "Generator model for the DualGAN"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DualGANGenerator,title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generator\n",
    "Let's test for a few things:\n",
    "1. The generator can indeed be initialized correctly\n",
    "2. A random image can be passed into the model successfully with the correct size output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a random batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DualGANGenerator(3)\n",
    "with torch.no_grad():\n",
    "    out1 = m(img1)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(out1.shape, torch.Size([4, 3, 256, 256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "As described in the DualGAN paper, we will use a 70x70 PatchGAN, the same discriminator for the CycleGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D = discriminator(3)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DualGAN(nn.Module, PyTorchModelHubMixin):\n",
    "    \"\"\"\n",
    "    DualGAN model. \\n\n",
    "    When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
    "\n",
    "    Attributes: \\n\n",
    "    `G_A` (`nn.Module`): takes real input B and generates fake input A \\n\n",
    "    `G_B` (`nn.Module`): takes real input A and generates fake input B \\n\n",
    "    `D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \\n\n",
    "    `D_B` (`nn.Module`): trained to make the difference between real input B and fake input B \\n\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in:int=3, n_features:int=64, disc_layers:int=3, lsgan:bool=False, \n",
    "                 drop:float=0., norm_layer:nn.Module=None):\n",
    "        \"\"\"\n",
    "        Constructor for DualGAN model.\n",
    "        \n",
    "        Arguments: \\n\n",
    "        `ch_in` (`int`): Number of input channels (default=3) \\n\n",
    "        `n_features` (`int`): Number of input features (default=64) \\n\n",
    "        `disc_layers` (`int`): Number of discriminator layers (default=3) \\n\n",
    "        `lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \\n\n",
    "        `norm_layer` (`nn.Module`): Type of normalization layer to use in the models (default=None)\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        #G_A: takes real input B and generates fake input A\n",
    "        #G_B: takes real input A and generates fake input B\n",
    "        #D_A: trained to make the difference between real input A and fake input A\n",
    "        #D_B: trained to make the difference between real input B and fake input B\n",
    "        self.D_A = discriminator(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n",
    "        self.D_B = discriminator(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n",
    "        self.G_A = DualGANGenerator(ch_in); self.G_A.apply(weights_init_normal)\n",
    "        self.G_B = DualGANGenerator(ch_in); self.G_B.apply(weights_init_normal)\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function for DualGAN model. The input is a tuple of a batch of real images from both domains A and B.\"\"\"\n",
    "        real_A, real_B = input\n",
    "        fake_A, fake_B = self.G_A(real_B), self.G_B(real_A)\n",
    "        idt_A, idt_B = self.G_A(real_A), self.G_B(real_B) #optional identity loss\n",
    "        return [fake_A, fake_B, idt_A, idt_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"DualGAN\" class=\"doc_header\"><code>class</code> <code>DualGAN</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>DualGAN</code>(**`ch_in`**:`int`=*`3`*, **`n_features`**:`int`=*`64`*, **`disc_layers`**:`int`=*`3`*, **`lsgan`**:`bool`=*`False`*, **`drop`**:`float`=*`0.0`*, **`norm_layer`**:`Module`=*`None`*) :: `Module`\n",
       "\n",
       "DualGAN model. \n",
       "\n",
       "When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
       "\n",
       "Attributes: \n",
       "\n",
       "`G_A` (`nn.Module`): takes real input B and generates fake input A \n",
       "\n",
       "`G_B` (`nn.Module`): takes real input A and generates fake input B \n",
       "\n",
       "`D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \n",
       "\n",
       "`D_B` (`nn.Module`): trained to make the difference between real input B and fake input B "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DualGAN,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DualGAN.__init__\" class=\"doc_header\"><code>DualGAN.__init__</code><a href=\"__main__.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DualGAN.__init__</code>(**`ch_in`**:`int`=*`3`*, **`n_features`**:`int`=*`64`*, **`disc_layers`**:`int`=*`3`*, **`lsgan`**:`bool`=*`False`*, **`drop`**:`float`=*`0.0`*, **`norm_layer`**:`Module`=*`None`*)\n",
       "\n",
       "Constructor for DualGAN model.\n",
       "\n",
       "Arguments: \n",
       "\n",
       "`ch_in` (`int`): Number of input channels (default=3) \n",
       "\n",
       "`n_features` (`int`): Number of input features (default=64) \n",
       "\n",
       "`disc_layers` (`int`): Number of discriminator layers (default=3) \n",
       "\n",
       "`lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \n",
       "\n",
       "`norm_layer` (`nn.Module`): Type of normalization layer to use in the models (default=None)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DualGAN.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DualGAN.forward\" class=\"doc_header\"><code>DualGAN.forward</code><a href=\"__main__.py#L37\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DualGAN.forward</code>(**`input`**)\n",
       "\n",
       "Forward function for DualGAN model. The input is a tuple of a batch of real images from both domains A and B."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DualGAN.forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model tests\n",
    "\n",
    "Again, let's check that the model can be called sucsessfully and outputs the correct shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dualgan_model = DualGAN()\n",
    "img1 = torch.randn(4,3,256,256)\n",
    "img2 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 1.57 s, total: 20.5 s\n",
      "Wall time: 447 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad(): dualgan_output = dualgan_model((img1,img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(dualgan_output),4)\n",
    "for output_batch in dualgan_output:\n",
    "    test_eq(output_batch.shape,img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/tmabraham/upit-dualgan-test into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f43a8f7708e4b9d9e584634316926b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 3.34k/340M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/tmabraham/upit-dualgan-test\n",
      "   dccaa0f..f8d92db  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/tmabraham/upit-dualgan-test/commit/f8d92db7854429ca64335e9ab698d7e7f2f44feb'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip\n",
    "dualgan_model.push_to_hub('upit-dualgan-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in HuggingFace Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b50febb8e244499fe23401c798f6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DualGAN(\n",
       "  (D_A): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       "  (D_B): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       "  (G_A): DualGANGenerator(\n",
       "    (down1): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (down2): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (down3): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (down4): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (down5): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (down6): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (down7): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up1): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up2): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up3): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up4): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up5): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up6): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (G_B): DualGANGenerator(\n",
       "    (down1): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (down2): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (down3): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (down4): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (down5): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (down6): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): LeakyReLU(negative_slope=0.2)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (down7): UNetDown(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up1): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up2): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up3): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (up4): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up5): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (up6): UNetUp(\n",
       "      (model): Sequential(\n",
       "        (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip\n",
    "#hide_output\n",
    "dualgan_model.from_pretrained('tmabraham/upit-dualgan-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_models.cyclegan.ipynb.\n",
      "Converted 01b_models.junyanz.ipynb.\n",
      "Converted 02_data.unpaired.ipynb.\n",
      "Converted 03_train.cyclegan.ipynb.\n",
      "Converted 04_inference.cyclegan.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_tracking.wandb.ipynb.\n",
      "Converted 07_models.dualgan.ipynb.\n",
      "Converted 08_train.dualgan.ipynb.\n",
      "Converted 09_models.ganilla.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
