{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `01b_models.junyanz.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taken from here:\n",
    "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py\n",
    "\n",
    "Was used before to confirm fastai implementation is correct. Not used elsewhere in the `UPIT` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models.junyanz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Helper Functions\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    \"\"\"Return a normalization layer\n",
    "\n",
    "    Parameters:\n",
    "        norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
    "\n",
    "    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
    "    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n",
    "    \"\"\"\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "    elif norm_type == 'none':\n",
    "        def norm_layer(x): return Identity()\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, opt):\n",
    "    \"\"\"Return a learning rate scheduler\n",
    "\n",
    "    Parameters:\n",
    "        optimizer          -- the optimizer of the network\n",
    "        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions．　\n",
    "                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n",
    "\n",
    "    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
    "    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
    "    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n",
    "    See https://pytorch.org/docs/stable/optim.html for more details.\n",
    "    \"\"\"\n",
    "    if opt.lr_policy == 'linear':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + opt.epoch_count - opt.n_epochs) / float(opt.n_epochs_decay + 1)\n",
    "            return lr_l\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif opt.lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
    "    elif opt.lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    elif opt.lr_policy == 'cosine':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=opt.n_epochs, eta_min=0)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Parameters:\n",
    "        net (network)   -- network to be initialized\n",
    "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
    "\n",
    "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
    "    work better for some applications. Feel free to try yourself.\n",
    "    \"\"\"\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>\n",
    "\n",
    "\n",
    "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
    "    Parameters:\n",
    "        net (network)      -- the network to be initialized\n",
    "        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "\n",
    "    Return an initialized network.\n",
    "    \"\"\"\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert(torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
    "    init_weights(net, init_type, init_gain=init_gain)\n",
    "    return net\n",
    "\n",
    "\n",
    "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Create a generator\n",
    "\n",
    "    Parameters:\n",
    "        input_nc (int) -- the number of channels in input images\n",
    "        output_nc (int) -- the number of channels in output images\n",
    "        ngf (int) -- the number of filters in the last conv layer\n",
    "        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n",
    "        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n",
    "        use_dropout (bool) -- if use dropout layers.\n",
    "        init_type (str)    -- the name of our initialization method.\n",
    "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "\n",
    "    Returns a generator\n",
    "\n",
    "    Our current implementation provides two types of generators:\n",
    "        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
    "        The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
    "\n",
    "        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n",
    "        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n",
    "        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n",
    "\n",
    "\n",
    "    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n",
    "    \"\"\"\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netG == 'resnet_9blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9)\n",
    "    elif netG == 'resnet_6blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6)\n",
    "    elif netG == 'unet_128':\n",
    "        net = UnetGenerator(input_nc, output_nc, 7, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "    elif netG == 'unet_256':\n",
    "        net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "    else:\n",
    "        raise NotImplementedError('Generator model name [%s] is not recognized' % netG)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "\n",
    "def define_D(input_nc, ndf, netD, n_layers_D=3, norm='batch', init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Create a discriminator\n",
    "\n",
    "    Parameters:\n",
    "        input_nc (int)     -- the number of channels in input images\n",
    "        ndf (int)          -- the number of filters in the first conv layer\n",
    "        netD (str)         -- the architecture's name: basic | n_layers | pixel\n",
    "        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n",
    "        norm (str)         -- the type of normalization layers used in the network.\n",
    "        init_type (str)    -- the name of the initialization method.\n",
    "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "\n",
    "    Returns a discriminator\n",
    "\n",
    "    Our current implementation provides three types of discriminators:\n",
    "        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n",
    "        It can classify whether 70×70 overlapping patches are real or fake.\n",
    "        Such a patch-level discriminator architecture has fewer parameters\n",
    "        than a full-image discriminator and can work on arbitrarily-sized images\n",
    "        in a fully convolutional fashion.\n",
    "\n",
    "        [n_layers]: With this mode, you can specify the number of conv layers in the discriminator\n",
    "        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n",
    "\n",
    "        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n",
    "        It encourages greater color diversity but has no effect on spatial statistics.\n",
    "\n",
    "    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n",
    "    \"\"\"\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netD == 'basic':  # default PatchGAN classifier\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer)\n",
    "    elif netD == 'n_layers':  # more options\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer)\n",
    "    elif netD == 'pixel':     # classify if each pixel is real or fake\n",
    "        net = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer)\n",
    "    else:\n",
    "        raise NotImplementedError('Discriminator model name [%s] is not recognized' % netD)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Classes\n",
    "##############################################################################\n",
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Define different GAN objectives.\n",
    "\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
    "        \"\"\" Initialize the GANLoss class.\n",
    "\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_fake_label (bool) - - label of a fake image\n",
    "\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        self.gan_mode = gan_mode\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode in ['wgangp']:\n",
    "            self.loss = None\n",
    "        else:\n",
    "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        \"\"\"Create label tensors with the same size as the input.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            A label tensor filled with ground truth label, and with the size of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
    "\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "\n",
    "        Returns:\n",
    "            the calculated loss.\n",
    "        \"\"\"\n",
    "        if self.gan_mode in ['lsgan', 'vanilla']:\n",
    "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "            loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgangp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "def cal_gradient_penalty(netD, real_data, fake_data, device, type='mixed', constant=1.0, lambda_gp=10.0):\n",
    "    \"\"\"Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n",
    "\n",
    "    Arguments:\n",
    "        netD (network)              -- discriminator network\n",
    "        real_data (tensor array)    -- real images\n",
    "        fake_data (tensor array)    -- generated images from the generator\n",
    "        device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
    "        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n",
    "        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n",
    "        lambda_gp (float)           -- weight for this loss\n",
    "\n",
    "    Returns the gradient penalty loss\n",
    "    \"\"\"\n",
    "    if lambda_gp > 0.0:\n",
    "        if type == 'real':   # either use real images, fake images, or a linear interpolation of two.\n",
    "            interpolatesv = real_data\n",
    "        elif type == 'fake':\n",
    "            interpolatesv = fake_data\n",
    "        elif type == 'mixed':\n",
    "            alpha = torch.rand(real_data.shape[0], 1, device=device)\n",
    "            alpha = alpha.expand(real_data.shape[0], real_data.nelement() // real_data.shape[0]).contiguous().view(*real_data.shape)\n",
    "            interpolatesv = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "        else:\n",
    "            raise NotImplementedError('{} not implemented'.format(type))\n",
    "        interpolatesv.requires_grad_(True)\n",
    "        disc_interpolates = netD(interpolatesv)\n",
    "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolatesv,\n",
    "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                                        create_graph=True, retain_graph=True, only_inputs=True)\n",
    "        gradients = gradients[0].view(real_data.size(0), -1)  # flat the data\n",
    "        gradient_penalty = (((gradients + 1e-16).norm(2, dim=1) - constant) ** 2).mean() * lambda_gp        # added eps\n",
    "        return gradient_penalty, gradients\n",
    "    else:\n",
    "        return 0.0, None\n",
    "\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        \"\"\"Construct a Resnet-based generator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)      -- the number of channels in input images\n",
    "            output_nc (int)     -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Initialize the Resnet block\n",
    "\n",
    "        A resnet block is a conv block with skip connections\n",
    "        We construct a conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> function.\n",
    "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Construct a convolutional block.\n",
    "\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "\n",
    "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
    "        \"\"\"\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out\n",
    "\n",
    "\n",
    "class UnetGenerator(nn.Module):\n",
    "    \"\"\"Create a Unet-based generator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, num_downs, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet generator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
    "                                image of size 128x128 will become of size 1x1 # at the bottleneck\n",
    "            ngf (int)       -- the number of filters in the last conv layer\n",
    "            norm_layer      -- normalization layer\n",
    "\n",
    "        We construct the U-Net from the innermost layer to the outermost layer.\n",
    "        It is a recursive process.\n",
    "        \"\"\"\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)  # add the innermost layer\n",
    "        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  # add the outermost layer\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    \"\"\"Defines the Unet submodule with skip connection.\n",
    "        X -------------------identity----------------------\n",
    "        |-- downsampling -- |submodule| -- upsampling --|\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet submodule with skip connections.\n",
    "\n",
    "        Parameters:\n",
    "            outer_nc (int) -- the number of filters in the outer conv layer\n",
    "            inner_nc (int) -- the number of filters in the inner conv layer\n",
    "            input_nc (int) -- the number of channels in input images/features\n",
    "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
    "            outermost (bool)    -- if this module is the outermost module\n",
    "            innermost (bool)    -- if this module is the innermost module\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "        \"\"\"\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:   # add skip connections\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class PixelDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a 1x1 PatchGAN discriminator (pixelGAN)\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a 1x1 PatchGAN discriminator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(PixelDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        self.net = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=1, stride=1, padding=0),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=1, stride=1, padding=0, bias=use_bias),\n",
    "            norm_layer(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf * 2, 1, kernel_size=1, stride=1, padding=0, bias=use_bias)]\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.net(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
