{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN model\n",
    "\n",
    "> Defines the CycleGAN model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.cyclegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from fastai.basics import *\n",
    "from typing import List\n",
    "from fastai.vision.gan import *\n",
    "from huggingface_hub import PyTorchModelHubMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from upit.models.junyanz import define_G, define_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the models that were introduced in the [cycleGAN paper](https://arxiv.org/abs/1703.10593)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convT_norm_relu(ch_in:int, ch_out:int, norm_layer:nn.Module, ks:int=3, stride:int=2, bias:bool=True):\n",
    "    return [nn.ConvTranspose2d(ch_in, ch_out, kernel_size=ks, stride=stride, padding=1, output_padding=1, bias=bias),\n",
    "            norm_layer(ch_out), nn.ReLU(True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"convT_norm_relu\" class=\"doc_header\"><code>convT_norm_relu</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>convT_norm_relu</code>(**`ch_in`**:`int`, **`ch_out`**:`int`, **`norm_layer`**:`Module`, **`ks`**:`int`=*`3`*, **`stride`**:`int`=*`2`*, **`bias`**:`bool`=*`True`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(convT_norm_relu,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_conv_norm_relu(ch_in:int, ch_out:int, pad_mode:str, norm_layer:nn.Module, ks:int=3, bias:bool=True, \n",
    "                       pad=1, stride:int=1, activ:bool=True, init=nn.init.kaiming_normal_, init_gain:int=0.02)->List[nn.Module]:\n",
    "    layers = []\n",
    "    if pad_mode == 'reflection': layers.append(nn.ReflectionPad2d(pad))\n",
    "    elif pad_mode == 'border':   layers.append(nn.ReplicationPad2d(pad))\n",
    "    p = pad if pad_mode == 'zeros' else 0\n",
    "    conv = nn.Conv2d(ch_in, ch_out, kernel_size=ks, padding=p, stride=stride, bias=bias)\n",
    "    if init:\n",
    "        if init == nn.init.normal_:\n",
    "            init(conv.weight, 0.0, init_gain)\n",
    "        else:\n",
    "            init(conv.weight)\n",
    "        if hasattr(conv, 'bias') and hasattr(conv.bias, 'data'): conv.bias.data.fill_(0.)\n",
    "    layers += [conv, norm_layer(ch_out)]\n",
    "    if activ: layers.append(nn.ReLU(inplace=True))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"pad_conv_norm_relu\" class=\"doc_header\"><code>pad_conv_norm_relu</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>pad_conv_norm_relu</code>(**`ch_in`**:`int`, **`ch_out`**:`int`, **`pad_mode`**:`str`, **`norm_layer`**:`Module`, **`ks`**:`int`=*`3`*, **`bias`**:`bool`=*`True`*, **`pad`**=*`1`*, **`stride`**:`int`=*`1`*, **`activ`**:`bool`=*`True`*, **`init`**=*`kaiming_normal_`*, **`init_gain`**:`int`=*`0.02`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(pad_conv_norm_relu,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"nn.Module for the ResNet Block\"\n",
    "    def __init__(self, dim:int, pad_mode:str='reflection', norm_layer:nn.Module=None, dropout:float=0., bias:bool=True):\n",
    "        super().__init__()\n",
    "        assert pad_mode in ['zeros', 'reflection', 'border'], f'padding {pad_mode} not implemented.'\n",
    "        norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "        layers = pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias=bias)\n",
    "        if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "        layers += pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias=bias, activ=False)\n",
    "        self.conv_block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"ResnetBlock\" class=\"doc_header\"><code>class</code> <code>ResnetBlock</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>ResnetBlock</code>(**`dim`**:`int`, **`pad_mode`**:`str`=*`'reflection'`*, **`norm_layer`**:`Module`=*`None`*, **`dropout`**:`float`=*`0.0`*, **`bias`**:`bool`=*`True`*) :: `Module`\n",
       "\n",
       "nn.Module for the ResNet Block"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ResnetBlock,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet_generator(ch_in:int, ch_out:int, n_ftrs:int=64, norm_layer:nn.Module=None, \n",
    "                     dropout:float=0., n_blocks:int=9, pad_mode:str='reflection')->nn.Module:\n",
    "    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "    bias = (norm_layer == nn.InstanceNorm2d)\n",
    "    layers = pad_conv_norm_relu(ch_in, n_ftrs, 'reflection', norm_layer, pad=3, ks=7, bias=bias)\n",
    "    for i in range(2):\n",
    "        layers += pad_conv_norm_relu(n_ftrs, n_ftrs *2, 'zeros', norm_layer, stride=2, bias=bias)\n",
    "        n_ftrs *= 2\n",
    "    layers += [ResnetBlock(n_ftrs, pad_mode, norm_layer, dropout, bias) for _ in range(n_blocks)]\n",
    "    for i in range(2):\n",
    "        layers += convT_norm_relu(n_ftrs, n_ftrs//2, norm_layer, bias=bias)\n",
    "        n_ftrs //= 2\n",
    "    layers += [nn.ReflectionPad2d(3), nn.Conv2d(n_ftrs, ch_out, kernel_size=7, padding=0), nn.Tanh()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"resnet_generator\" class=\"doc_header\"><code>resnet_generator</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>resnet_generator</code>(**`ch_in`**:`int`, **`ch_out`**:`int`, **`n_ftrs`**:`int`=*`64`*, **`norm_layer`**:`Module`=*`None`*, **`dropout`**:`float`=*`0.0`*, **`n_blocks`**:`int`=*`9`*, **`pad_mode`**:`str`=*`'reflection'`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(resnet_generator,title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test for a few things:\n",
    "1. The generator can indeed be initialized correctly\n",
    "2. A random image can be passed into the model successfully with the correct size output\n",
    "3. The CycleGAN generator is equivalent to the [original implementation](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/cycle_gan_model.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a random batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = resnet_generator(3,3)\n",
    "with torch.no_grad():\n",
    "    out1 = m(img1)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_junyanz = define_G(3,3,64,'resnet_9blocks', norm='instance')\n",
    "with torch.no_grad():\n",
    "    out2 = m_junyanz(img1)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compare_networks(a,b):\n",
    "    \"A simple function to compare the printed model representations as a proxy for actually comparing two models\"\n",
    "    assert len(a) == len(b)\n",
    "    for i in range(len(a)):\n",
    "        assert (a[i].__repr__()==b[i].__repr__()), f\"{a[i]} \\n and \\n {b[i]} \\n not equal (position {i})\"\n",
    "    print(\"Passed!\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "test_eq(out1.shape,img1.shape)\n",
    "test_eq(out2.shape,img1.shape)\n",
    "assert compare_networks(list(m_junyanz.children())[0],m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_norm_lr(ch_in:int, ch_out:int, norm_layer:nn.Module=None, ks:int=3, bias:bool=True, pad:int=1, stride:int=1, \n",
    "                 activ:bool=True, slope:float=0.2, init=nn.init.normal_, init_gain:int=0.02)->List[nn.Module]:\n",
    "    conv = nn.Conv2d(ch_in, ch_out, kernel_size=ks, padding=pad, stride=stride, bias=bias)\n",
    "    if init:\n",
    "        if init == nn.init.normal_:\n",
    "            init(conv.weight, 0.0, init_gain)\n",
    "        else:\n",
    "            init(conv.weight)\n",
    "        if hasattr(conv, 'bias') and hasattr(conv.bias, 'data'): conv.bias.data.fill_(0.)\n",
    "    layers = [conv]\n",
    "    if norm_layer is not None: layers.append(norm_layer(ch_out))\n",
    "    if activ: layers.append(nn.LeakyReLU(slope, inplace=True))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"conv_norm_lr\" class=\"doc_header\"><code>conv_norm_lr</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>conv_norm_lr</code>(**`ch_in`**:`int`, **`ch_out`**:`int`, **`norm_layer`**:`Module`=*`None`*, **`ks`**:`int`=*`3`*, **`bias`**:`bool`=*`True`*, **`pad`**:`int`=*`1`*, **`stride`**:`int`=*`1`*, **`activ`**:`bool`=*`True`*, **`slope`**:`float`=*`0.2`*, **`init`**=*`normal_`*, **`init_gain`**:`int`=*`0.02`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(conv_norm_lr,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def discriminator(ch_in:int, n_ftrs:int=64, n_layers:int=3, norm_layer:nn.Module=None, sigmoid:bool=False)->nn.Module:\n",
    "    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "    bias = (norm_layer == nn.InstanceNorm2d)\n",
    "    layers = conv_norm_lr(ch_in, n_ftrs, ks=4, stride=2, pad=1)\n",
    "    for i in range(n_layers-1):\n",
    "        new_ftrs = 2*n_ftrs if i <= 3 else n_ftrs\n",
    "        layers += conv_norm_lr(n_ftrs, new_ftrs, norm_layer, ks=4, stride=2, pad=1, bias=bias)\n",
    "        n_ftrs = new_ftrs\n",
    "    new_ftrs = 2*n_ftrs if n_layers <=3 else n_ftrs\n",
    "    layers += conv_norm_lr(n_ftrs, new_ftrs, norm_layer, ks=4, stride=1, pad=1, bias=bias)\n",
    "    layers.append(nn.Conv2d(new_ftrs, 1, kernel_size=4, stride=1, padding=1))\n",
    "    if sigmoid: layers.append(nn.Sigmoid())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"discriminator\" class=\"doc_header\"><code>discriminator</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>discriminator</code>(**`ch_in`**:`int`, **`n_ftrs`**:`int`=*`64`*, **`n_layers`**:`int`=*`3`*, **`norm_layer`**:`Module`=*`None`*, **`sigmoid`**:`bool`=*`False`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(discriminator,title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test discriminator\n",
    "Let's test for similar things:\n",
    "1. The discriminator can indeed be initialized correctly\n",
    "2. A random image can be passed into the discriminator successfully with the correct size output\n",
    "3. The CycleGAN discriminator is equivalent to the [original implementation](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/cycle_gan_model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 30, 30])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = discriminator(3)\n",
    "with torch.no_grad():\n",
    "    out1 = d(img1)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 30, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_junyanz = define_D(3,64,'basic',norm='instance')\n",
    "with torch.no_grad():\n",
    "    out2 = d_junyanz(img1)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "test_eq(out1.shape,torch.Size([4, 1, 30, 30]))\n",
    "test_eq(out2.shape,torch.Size([4, 1, 30, 30]))\n",
    "assert compare_networks(list(d_junyanz.children())[0],d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group two discriminators and two generators in a single model, then a `Callback` (defined in `02_cyclegan_training.ipynb`) will take care of training them properly. We use the `PyTorchModelHubMixin` to provide support for pushing to and loading from the [HuggingFace Hub](https://huggingface.co/docs/hub/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CycleGAN(nn.Module, PyTorchModelHubMixin):\n",
    "    \"\"\"\n",
    "    CycleGAN model. \\n\n",
    "    When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
    "    Also outputs identity images after passing the images into generators that outputs its domain type (needed for identity loss).\n",
    "\n",
    "    Attributes: \\n\n",
    "    `G_A` (`nn.Module`): takes real input B and generates fake input A \\n\n",
    "    `G_B` (`nn.Module`): takes real input A and generates fake input B \\n\n",
    "    `D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \\n\n",
    "    `D_B` (`nn.Module`): trained to make the difference between real input B and fake input B \\n\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in:int=3, ch_out:int=3, n_features:int=64, disc_layers:int=3, gen_blocks:int=9, lsgan:bool=True, \n",
    "                 drop:float=0., norm_layer:nn.Module=None):\n",
    "        \"\"\"\n",
    "        Constructor for CycleGAN model.\n",
    "        \n",
    "        Arguments: \\n\n",
    "        `ch_in` (`int`): Number of input channels (default=3) \\n\n",
    "        `ch_out` (`int`): Number of output channels (default=3) \\n\n",
    "        `n_features` (`int`): Number of input features (default=64) \\n\n",
    "        `disc_layers` (`int`): Number of discriminator layers (default=3) \\n\n",
    "        `gen_blocks` (`int`): Number of residual blocks in the generator (default=9) \\n\n",
    "        `lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \\n\n",
    "        `drop` (`float`): Level of dropout (default=0) \\n\n",
    "        `norm_layer` (`nn.Module`): Type of normalization layer to use in the models (default=None)\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        #G_A: takes real input B and generates fake input A\n",
    "        #G_B: takes real input A and generates fake input B\n",
    "        #D_A: trained to make the difference between real input A and fake input A\n",
    "        #D_B: trained to make the difference between real input B and fake input B\n",
    "        self.D_A = discriminator(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n",
    "        self.D_B = discriminator(ch_in, n_features, disc_layers, norm_layer, sigmoid=not lsgan)\n",
    "        self.G_A = resnet_generator(ch_in, ch_out, n_features, norm_layer, drop, gen_blocks)\n",
    "        self.G_B = resnet_generator(ch_in, ch_out, n_features, norm_layer, drop, gen_blocks)\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function for CycleGAN model. The input is a tuple of a batch of real images from both domains A and B.\"\"\"\n",
    "        real_A, real_B = input\n",
    "        fake_A, fake_B = self.G_A(real_B), self.G_B(real_A)\n",
    "        idt_A, idt_B = self.G_A(real_A), self.G_B(real_B) #Needed for the identity loss during training.\n",
    "        return [fake_A, fake_B, idt_A, idt_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CycleGAN\" class=\"doc_header\"><code>class</code> <code>CycleGAN</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CycleGAN</code>(**`ch_in`**:`int`=*`3`*, **`ch_out`**:`int`=*`3`*, **`n_features`**:`int`=*`64`*, **`disc_layers`**:`int`=*`3`*, **`gen_blocks`**:`int`=*`9`*, **`lsgan`**:`bool`=*`True`*, **`drop`**:`float`=*`0.0`*, **`norm_layer`**:`Module`=*`None`*) :: `Module`\n",
       "\n",
       "CycleGAN model. \n",
       "\n",
       "When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
       "Also outputs identity images after passing the images into generators that outputs its domain type (needed for identity loss).\n",
       "\n",
       "Attributes: \n",
       "\n",
       "`G_A` (`nn.Module`): takes real input B and generates fake input A \n",
       "\n",
       "`G_B` (`nn.Module`): takes real input A and generates fake input B \n",
       "\n",
       "`D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \n",
       "\n",
       "`D_B` (`nn.Module`): trained to make the difference between real input B and fake input B "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CycleGAN,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CycleGAN.__init__\" class=\"doc_header\"><code>CycleGAN.__init__</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CycleGAN.__init__</code>(**`ch_in`**:`int`=*`3`*, **`ch_out`**:`int`=*`3`*, **`n_features`**:`int`=*`64`*, **`disc_layers`**:`int`=*`3`*, **`gen_blocks`**:`int`=*`9`*, **`lsgan`**:`bool`=*`True`*, **`drop`**:`float`=*`0.0`*, **`norm_layer`**:`Module`=*`None`*)\n",
       "\n",
       "Constructor for CycleGAN model.\n",
       "\n",
       "Arguments: \n",
       "\n",
       "`ch_in` (`int`): Number of input channels (default=3) \n",
       "\n",
       "`ch_out` (`int`): Number of output channels (default=3) \n",
       "\n",
       "`n_features` (`int`): Number of input features (default=64) \n",
       "\n",
       "`disc_layers` (`int`): Number of discriminator layers (default=3) \n",
       "\n",
       "`gen_blocks` (`int`): Number of residual blocks in the generator (default=9) \n",
       "\n",
       "`lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \n",
       "\n",
       "`drop` (`float`): Level of dropout (default=0) \n",
       "\n",
       "`norm_layer` (`nn.Module`): Type of normalization layer to use in the models (default=None)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CycleGAN.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CycleGAN.forward\" class=\"doc_header\"><code>CycleGAN.forward</code><a href=\"__main__.py#L41\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CycleGAN.forward</code>(**`input`**)\n",
       "\n",
       "Forward function for CycleGAN model. The input is a tuple of a batch of real images from both domains A and B."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CycleGAN.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModelHubMixin.push_to_hub\" class=\"doc_header\"><code>ModelHubMixin.push_to_hub</code><a href=\"huggingface_hub/hub_mixin.py#L211\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModelHubMixin.push_to_hub</code>(**`repo_path_or_name`**:`Optional`\\[`str`\\]=*`None`*, **`repo_url`**:`Optional`\\[`str`\\]=*`None`*, **`commit_message`**:`Optional`\\[`str`\\]=*`'Add model'`*, **`organization`**:`Optional`\\[`str`\\]=*`None`*, **`private`**:`Optional`\\[`bool`\\]=*`None`*, **`api_endpoint`**:`Optional`\\[`str`\\]=*`None`*, **`use_auth_token`**:`Union`\\[`bool`, `str`, `NoneType`\\]=*`None`*, **`git_user`**:`Optional`\\[`str`\\]=*`None`*, **`git_email`**:`Optional`\\[`str`\\]=*`None`*, **`config`**:`Optional`\\[`dict`\\]=*`None`*)\n",
       "\n",
       "Upload model checkpoint or tokenizer files to the Hub while\n",
       "synchronizing a local clone of the repo in `repo_path_or_name`.\n",
       "\n",
       "Parameters:\n",
       "    repo_path_or_name (`str`, *optional*):\n",
       "        Can either be a repository name for your model or tokenizer in\n",
       "        the Hub or a path to a local folder (in which case the\n",
       "        repository will have the name of that local folder). If not\n",
       "        specified, will default to the name given by `repo_url` and a\n",
       "        local directory with that name will be created.\n",
       "    repo_url (`str`, *optional*):\n",
       "        Specify this in case you want to push to an existing repository\n",
       "        in the hub. If unspecified, a new repository will be created in\n",
       "        your namespace (unless you specify an `organization`) with\n",
       "        `repo_name`.\n",
       "    commit_message (`str`, *optional*):\n",
       "        Message to commit while pushing. Will default to `\"add config\"`,\n",
       "        `\"add tokenizer\"` or `\"add model\"` depending on the type of the\n",
       "        class.\n",
       "    organization (`str`, *optional*):\n",
       "        Organization in which you want to push your model or tokenizer\n",
       "        (you must be a member of this organization).\n",
       "    private (`bool`, *optional*):\n",
       "        Whether the repository created should be private.\n",
       "    api_endpoint (`str`, *optional*):\n",
       "        The API endpoint to use when pushing the model to the hub.\n",
       "    use_auth_token (`bool` or `str`, *optional*):\n",
       "        The token to use as HTTP bearer authorization for remote files.\n",
       "        If `True`, will use the token generated when running\n",
       "        `transformers-cli login` (stored in `~/.huggingface`). Will\n",
       "        default to `True` if `repo_url` is not specified.\n",
       "    git_user (`str`, *optional*):\n",
       "        will override the `git config user.name` for committing and\n",
       "        pushing files to the hub.\n",
       "    git_email (`str`, *optional*):\n",
       "        will override the `git config user.email` for committing and\n",
       "        pushing files to the hub.\n",
       "    config (`dict`, *optional*):\n",
       "        Configuration object to be saved alongside the model weights.\n",
       "\n",
       "\n",
       "Returns:\n",
       "    The url of the commit of your model in the given repository."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CycleGAN.push_to_hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModelHubMixin.from_pretrained\" class=\"doc_header\"><code>ModelHubMixin.from_pretrained</code><a href=\"huggingface_hub/hub_mixin.py#L73\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModelHubMixin.from_pretrained</code>(**`pretrained_model_name_or_path`**:`str`, **`force_download`**:`bool`=*`False`*, **`resume_download`**:`bool`=*`False`*, **`proxies`**:`typing.Dict`=*`None`*, **`use_auth_token`**:`Optional`\\[`str`\\]=*`None`*, **`cache_dir`**:`Optional`\\[`str`\\]=*`None`*, **`local_files_only`**:`bool`=*`False`*, **\\*\\*`model_kwargs`**)\n",
       "\n",
       "Instantiate a pretrained PyTorch model from a pre-trained model\n",
       "        configuration from huggingface-hub. The model is set in\n",
       "        evaluation mode by default using `model.eval()` (Dropout modules\n",
       "        are deactivated). To train the model, you should first set it\n",
       "        back in training mode with `model.train()`.\n",
       "\n",
       "        Parameters:\n",
       "            pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
       "                Can be either:\n",
       "                    - A string, the `model id` of a pretrained model\n",
       "                      hosted inside a model repo on huggingface.co.\n",
       "                      Valid model ids can be located at the root-level,\n",
       "                      like `bert-base-uncased`, or namespaced under a\n",
       "                      user or organization name, like\n",
       "                      `dbmdz/bert-base-german-cased`.\n",
       "                    - You can add `revision` by appending `@` at the end\n",
       "                      of model_id simply like this:\n",
       "                      `dbmdz/bert-base-german-cased@main` Revision is\n",
       "                      the specific model version to use. It can be a\n",
       "                      branch name, a tag name, or a commit id, since we\n",
       "                      use a git-based system for storing models and\n",
       "                      other artifacts on huggingface.co, so `revision`\n",
       "                      can be any identifier allowed by git.\n",
       "                    - A path to a `directory` containing model weights\n",
       "                      saved using\n",
       "                      [`~transformers.PreTrainedModel.save_pretrained`],\n",
       "                      e.g., `./my_model_directory/`.\n",
       "                    - `None` if you are both providing the configuration\n",
       "                      and state dictionary (resp. with keyword arguments\n",
       "                      `config` and `state_dict`).\n",
       "            force_download (`bool`, *optional*, defaults to `False`):\n",
       "                Whether to force the (re-)download of the model weights\n",
       "                and configuration files, overriding the cached versions\n",
       "                if they exist.\n",
       "            resume_download (`bool`, *optional*, defaults to `False`):\n",
       "                Whether to delete incompletely received files. Will\n",
       "                attempt to resume the download if such a file exists.\n",
       "            proxies (`Dict[str, str]`, *optional*):\n",
       "                A dictionary of proxy servers to use by protocol or\n",
       "                endpoint, e.g., `{'http': 'foo.bar:3128',\n",
       "                'http://hostname': 'foo.bar:4012'}`. The proxies are\n",
       "                used on each request.\n",
       "            use_auth_token (`str` or `bool`, *optional*):\n",
       "                The token to use as HTTP bearer authorization for remote\n",
       "                files. If `True`, will use the token generated when\n",
       "                running `transformers-cli login` (stored in\n",
       "                `~/.huggingface`).\n",
       "            cache_dir (`Union[str, os.PathLike]`, *optional*):\n",
       "                Path to a directory in which a downloaded pretrained\n",
       "                model configuration should be cached if the standard\n",
       "                cache should not be used.\n",
       "            local_files_only(`bool`, *optional*, defaults to `False`):\n",
       "                Whether to only look at local files (i.e., do not try to\n",
       "                download the model).\n",
       "            model_kwargs (`Dict`, *optional*):\n",
       "                model_kwargs will be passed to the model during\n",
       "                initialization\n",
       "\n",
       "        <Tip>\n",
       "\n",
       "        Passing `use_auth_token=True` is required when you want to use a\n",
       "        private model.\n",
       "\n",
       "        </Tip>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CycleGAN.from_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model tests\n",
    "\n",
    "Again, let's check that the model can be called sucsessfully and outputs the correct shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclegan_model = CycleGAN()\n",
    "img1 = torch.randn(4,3,256,256)\n",
    "img2 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 6.67 s, total: 1min 22s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad(): cyclegan_output = cyclegan_model((img1,img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(cyclegan_output),4)\n",
    "for output_batch in cyclegan_output:\n",
    "    test_eq(output_batch.shape,img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/tmabraham/upit-cyclegan-test into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95a20b273084e1a8d9ea94b3cdb7f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 3.34k/108M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/tmabraham/upit-cyclegan-test\n",
      "   a41e9e0..2331f7d  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/tmabraham/upit-cyclegan-test/commit/2331f7d345d719ac1fdfb10b2cddf58abd7931bb'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclegan_model.push_to_hub('upit-cyclegan-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in HuggingFace Hub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CycleGAN(\n",
       "  (D_A): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (D_B): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (G_A): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (18): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       "  (G_B): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (18): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "cyclegan_model.from_pretrained('tmabraham/upit-cyclegan-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_models.cyclegan.ipynb.\n",
      "Converted 01b_models.junyanz.ipynb.\n",
      "Converted 02_data.unpaired.ipynb.\n",
      "Converted 03_train.cyclegan.ipynb.\n",
      "Converted 04_inference.cyclegan.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_tracking.wandb.ipynb.\n",
      "Converted 07_models.dualgan.ipynb.\n",
      "Converted 08_train.dualgan.ipynb.\n",
      "Converted 09_models.ganilla.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
