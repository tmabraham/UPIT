{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN Inference Web App\n",
    "> A PyTorch-only, self-contained inference API (and web app demo) for CycleGAN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demo a deep learning model, it is often useful to have a simple web app demo. Here, I have a self-contained demo made with [Gradio](https://www.gradio.app/), which makes it as easy as a one-liner to make great web app demos.\n",
    "\n",
    "This notebook (and it's corresponding Python file) can be run independently, outside of this library. It only requires installation of PyTorch (even the CPU version) and Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Generator\n",
    "(again, but with minor fastai-independent changes since this is standalone code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifnone(a, b): # a fastai-specific (fastcore) function used below, redefined so it's independent\n",
    "    \"`b` if `a` is None else `a`\"\n",
    "    return b if a is None else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convT_norm_relu(ch_in:int, ch_out:int, norm_layer:nn.Module, ks:int=3, stride:int=2, bias:bool=True):\n",
    "    return [nn.ConvTranspose2d(ch_in, ch_out, kernel_size=ks, stride=stride, padding=1, output_padding=1, bias=bias),\n",
    "            norm_layer(ch_out), nn.ReLU(True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_conv_norm_relu(ch_in:int, ch_out:int, pad_mode:str, norm_layer:nn.Module, ks:int=3, bias:bool=True, \n",
    "                       pad=1, stride:int=1, activ:bool=True, init=nn.init.kaiming_normal_, init_gain:int=0.02)->List[nn.Module]:\n",
    "    layers = []\n",
    "    if pad_mode == 'reflection': layers.append(nn.ReflectionPad2d(pad))\n",
    "    elif pad_mode == 'border':   layers.append(nn.ReplicationPad2d(pad))\n",
    "    p = pad if pad_mode == 'zeros' else 0\n",
    "    conv = nn.Conv2d(ch_in, ch_out, kernel_size=ks, padding=p, stride=stride, bias=bias)\n",
    "    if init:\n",
    "        if init == nn.init.normal_:\n",
    "            init(conv.weight, 0.0, init_gain)\n",
    "        else:\n",
    "            init(conv.weight)\n",
    "        if hasattr(conv, 'bias') and hasattr(conv.bias, 'data'): conv.bias.data.fill_(0.)\n",
    "    layers += [conv, norm_layer(ch_out)]\n",
    "    if activ: layers.append(nn.ReLU(inplace=True))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    \"nn.Module for the ResNet Block\"\n",
    "    def __init__(self, dim:int, pad_mode:str='reflection', norm_layer:nn.Module=None, dropout:float=0., bias:bool=True):\n",
    "        super().__init__()\n",
    "        assert pad_mode in ['zeros', 'reflection', 'border'], f'padding {pad_mode} not implemented.'\n",
    "        norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "        layers = pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias=bias)\n",
    "        if dropout != 0: layers.append(nn.Dropout(dropout))\n",
    "        layers += pad_conv_norm_relu(dim, dim, pad_mode, norm_layer, bias=bias, activ=False)\n",
    "        self.conv_block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_generator(ch_in:int, ch_out:int, n_ftrs:int=64, norm_layer:nn.Module=None, \n",
    "                     dropout:float=0., n_blocks:int=9, pad_mode:str='reflection')->nn.Module:\n",
    "    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n",
    "    bias = (norm_layer == nn.InstanceNorm2d)\n",
    "    layers = pad_conv_norm_relu(ch_in, n_ftrs, 'reflection', norm_layer, pad=3, ks=7, bias=bias)\n",
    "    for i in range(2):\n",
    "        layers += pad_conv_norm_relu(n_ftrs, n_ftrs *2, 'zeros', norm_layer, stride=2, bias=bias)\n",
    "        n_ftrs *= 2\n",
    "    layers += [ResnetBlock(n_ftrs, pad_mode, norm_layer, dropout, bias) for _ in range(n_blocks)]\n",
    "    for i in range(2):\n",
    "        layers += convT_norm_relu(n_ftrs, n_ftrs//2, norm_layer, bias=bias)\n",
    "        n_ftrs //= 2\n",
    "    layers += [nn.ReflectionPad2d(3), nn.Conv2d(n_ftrs, ch_out, kernel_size=7, padding=0), nn.Tanh()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "  (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (11): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (12): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (13): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (14): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (15): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (16): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (17): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (18): ResnetBlock(\n",
       "    (conv_block): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (21): ReLU(inplace=True)\n",
       "  (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (24): ReLU(inplace=True)\n",
       "  (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "  (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (27): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet_generator(ch_in=3, ch_out=3, n_ftrs=64, norm_layer=None, dropout=0, n_blocks=9)\n",
    "model.load_state_dict(torch.load('generator.pth'))\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "totensor = torchvision.transforms.ToTensor()\n",
    "normalize_fn = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "\n",
    "def predict(input):\n",
    "    im = normalize_fn(totensor(input))\n",
    "    print(im.shape)\n",
    "    preds = model(im.unsqueeze(0).cuda())/2 + 0.5\n",
    "    print(preds.shape)\n",
    "    return topilimage(preds.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Gradio interface:\n",
    "Two steps:\n",
    "1. Define interface\n",
    "2. Launch interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7861/\n",
      "Running on External URL: https://39107.gradio.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.networking.serve_files_in_background.<locals>.HTTPServer at 0x7fdd703a5b50>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " 'https://39107.gradio.app')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([1, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "gr_interface = gr.Interface(fn=predict, inputs=gr.inputs.Image(shape=(512, 512)), outputs=\"image\", title='Horse-to-Zebra CycleGAN')\n",
    "gr_interface.launch(inline=False,share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
