{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: models.junyanz.html\n",
    "title: Original CycleGAN implementation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taken from here:\n",
    "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py\n",
    "\n",
    "Was used before to confirm fastai implementation is correct. Not used elsewhere in the `UPIT` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L594){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PixelDiscriminator\n",
       "\n",
       ">      PixelDiscriminator (input_nc, ndf=64, norm_layer=<class\n",
       ">                          'torch.nn.modules.batchnorm.BatchNorm2d'>)\n",
       "\n",
       "Defines a 1x1 PatchGAN discriminator (pixelGAN)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L594){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PixelDiscriminator\n",
       "\n",
       ">      PixelDiscriminator (input_nc, ndf=64, norm_layer=<class\n",
       ">                          'torch.nn.modules.batchnorm.BatchNorm2d'>)\n",
       "\n",
       "Defines a 1x1 PatchGAN discriminator (pixelGAN)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PixelDiscriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L546){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NLayerDiscriminator\n",
       "\n",
       ">      NLayerDiscriminator (input_nc, ndf=64, n_layers=3, norm_layer=<class\n",
       ">                           'torch.nn.modules.batchnorm.BatchNorm2d'>)\n",
       "\n",
       "Defines a PatchGAN discriminator"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L546){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NLayerDiscriminator\n",
       "\n",
       ">      NLayerDiscriminator (input_nc, ndf=64, n_layers=3, norm_layer=<class\n",
       ">                           'torch.nn.modules.batchnorm.BatchNorm2d'>)\n",
       "\n",
       "Defines a PatchGAN discriminator"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(NLayerDiscriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L476){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UnetSkipConnectionBlock\n",
       "\n",
       ">      UnetSkipConnectionBlock (outer_nc, inner_nc, input_nc=None,\n",
       ">                               submodule=None, outermost=False,\n",
       ">                               innermost=False, norm_layer=<class\n",
       ">                               'torch.nn.modules.batchnorm.BatchNorm2d'>,\n",
       ">                               use_dropout=False)\n",
       "\n",
       "Defines the Unet submodule with skip connection.\n",
       "X -------------------identity----------------------\n",
       "|-- downsampling -- |submodule| -- upsampling --|"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L476){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UnetSkipConnectionBlock\n",
       "\n",
       ">      UnetSkipConnectionBlock (outer_nc, inner_nc, input_nc=None,\n",
       ">                               submodule=None, outermost=False,\n",
       ">                               innermost=False, norm_layer=<class\n",
       ">                               'torch.nn.modules.batchnorm.BatchNorm2d'>,\n",
       ">                               use_dropout=False)\n",
       "\n",
       "Defines the Unet submodule with skip connection.\n",
       "X -------------------identity----------------------\n",
       "|-- downsampling -- |submodule| -- upsampling --|"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(UnetSkipConnectionBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L444){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UnetGenerator\n",
       "\n",
       ">      UnetGenerator (input_nc, output_nc, num_downs, ngf=64, norm_layer=<class\n",
       ">                     'torch.nn.modules.batchnorm.BatchNorm2d'>,\n",
       ">                     use_dropout=False)\n",
       "\n",
       "Create a Unet-based generator"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L444){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UnetGenerator\n",
       "\n",
       ">      UnetGenerator (input_nc, output_nc, num_downs, ngf=64, norm_layer=<class\n",
       ">                     'torch.nn.modules.batchnorm.BatchNorm2d'>,\n",
       ">                     use_dropout=False)\n",
       "\n",
       "Create a Unet-based generator"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(UnetGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L384){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResnetBlock\n",
       "\n",
       ">      ResnetBlock (dim, padding_type, norm_layer, use_dropout, use_bias)\n",
       "\n",
       "Define a Resnet block"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L384){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResnetBlock\n",
       "\n",
       ">      ResnetBlock (dim, padding_type, norm_layer, use_dropout, use_bias)\n",
       "\n",
       "Define a Resnet block"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ResnetBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L323){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResnetGenerator\n",
       "\n",
       ">      ResnetGenerator (input_nc, output_nc, ngf=64, norm_layer=<class\n",
       ">                       'torch.nn.modules.batchnorm.BatchNorm2d'>,\n",
       ">                       use_dropout=False, n_blocks=6, padding_type='reflect')\n",
       "\n",
       "Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
       "\n",
       "We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L323){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResnetGenerator\n",
       "\n",
       ">      ResnetGenerator (input_nc, output_nc, ngf=64, norm_layer=<class\n",
       ">                       'torch.nn.modules.batchnorm.BatchNorm2d'>,\n",
       ">                       use_dropout=False, n_blocks=6, padding_type='reflect')\n",
       "\n",
       "Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
       "\n",
       "We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ResnetGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L286){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### cal_gradient_penalty\n",
       "\n",
       ">      cal_gradient_penalty (netD, real_data, fake_data, device, type='mixed',\n",
       ">                            constant=1.0, lambda_gp=10.0)\n",
       "\n",
       "Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n",
       "\n",
       "Arguments:\n",
       "    netD (network)              -- discriminator network\n",
       "    real_data (tensor array)    -- real images\n",
       "    fake_data (tensor array)    -- generated images from the generator\n",
       "    device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
       "    type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n",
       "    constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n",
       "    lambda_gp (float)           -- weight for this loss\n",
       "\n",
       "Returns the gradient penalty loss"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L286){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### cal_gradient_penalty\n",
       "\n",
       ">      cal_gradient_penalty (netD, real_data, fake_data, device, type='mixed',\n",
       ">                            constant=1.0, lambda_gp=10.0)\n",
       "\n",
       "Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n",
       "\n",
       "Arguments:\n",
       "    netD (network)              -- discriminator network\n",
       "    real_data (tensor array)    -- real images\n",
       "    fake_data (tensor array)    -- generated images from the generator\n",
       "    device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
       "    type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n",
       "    constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n",
       "    lambda_gp (float)           -- weight for this loss\n",
       "\n",
       "Returns the gradient penalty loss"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(cal_gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L217){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GANLoss\n",
       "\n",
       ">      GANLoss (gan_mode, target_real_label=1.0, target_fake_label=0.0)\n",
       "\n",
       "Define different GAN objectives.\n",
       "\n",
       "The GANLoss class abstracts away the need to create the target label tensor\n",
       "that has the same size as the input."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L217){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GANLoss\n",
       "\n",
       ">      GANLoss (gan_mode, target_real_label=1.0, target_fake_label=0.0)\n",
       "\n",
       "Define different GAN objectives.\n",
       "\n",
       "The GANLoss class abstracts away the need to create the target label tensor\n",
       "that has the same size as the input."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(GANLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L170){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### define_D\n",
       "\n",
       ">      define_D (input_nc, ndf, netD, n_layers_D=3, norm='batch',\n",
       ">                init_type='normal', init_gain=0.02, gpu_ids=[])\n",
       "\n",
       "Create a discriminator\n",
       "\n",
       "Parameters:\n",
       "    input_nc (int)     -- the number of channels in input images\n",
       "    ndf (int)          -- the number of filters in the first conv layer\n",
       "    netD (str)         -- the architecture's name: basic | n_layers | pixel\n",
       "    n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n",
       "    norm (str)         -- the type of normalization layers used in the network.\n",
       "    init_type (str)    -- the name of the initialization method.\n",
       "    init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
       "    gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
       "\n",
       "Returns a discriminator\n",
       "\n",
       "Our current implementation provides three types of discriminators:\n",
       "    [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n",
       "    It can classify whether 70×70 overlapping patches are real or fake.\n",
       "    Such a patch-level discriminator architecture has fewer parameters\n",
       "    than a full-image discriminator and can work on arbitrarily-sized images\n",
       "    in a fully convolutional fashion.\n",
       "\n",
       "    [n_layers]: With this mode, you can specify the number of conv layers in the discriminator\n",
       "    with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n",
       "\n",
       "    [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n",
       "    It encourages greater color diversity but has no effect on spatial statistics.\n",
       "\n",
       "The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L170){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### define_D\n",
       "\n",
       ">      define_D (input_nc, ndf, netD, n_layers_D=3, norm='batch',\n",
       ">                init_type='normal', init_gain=0.02, gpu_ids=[])\n",
       "\n",
       "Create a discriminator\n",
       "\n",
       "Parameters:\n",
       "    input_nc (int)     -- the number of channels in input images\n",
       "    ndf (int)          -- the number of filters in the first conv layer\n",
       "    netD (str)         -- the architecture's name: basic | n_layers | pixel\n",
       "    n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n",
       "    norm (str)         -- the type of normalization layers used in the network.\n",
       "    init_type (str)    -- the name of the initialization method.\n",
       "    init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
       "    gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
       "\n",
       "Returns a discriminator\n",
       "\n",
       "Our current implementation provides three types of discriminators:\n",
       "    [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n",
       "    It can classify whether 70×70 overlapping patches are real or fake.\n",
       "    Such a patch-level discriminator architecture has fewer parameters\n",
       "    than a full-image discriminator and can work on arbitrarily-sized images\n",
       "    in a fully convolutional fashion.\n",
       "\n",
       "    [n_layers]: With this mode, you can specify the number of conv layers in the discriminator\n",
       "    with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n",
       "\n",
       "    [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n",
       "    It encourages greater color diversity but has no effect on spatial statistics.\n",
       "\n",
       "The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(define_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L127){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### define_G\n",
       "\n",
       ">      define_G (input_nc, output_nc, ngf, netG, norm='batch',\n",
       ">                use_dropout=False, init_type='normal', init_gain=0.02,\n",
       ">                gpu_ids=[])\n",
       "\n",
       "Create a generator\n",
       "\n",
       "Parameters:\n",
       "    input_nc (int) -- the number of channels in input images\n",
       "    output_nc (int) -- the number of channels in output images\n",
       "    ngf (int) -- the number of filters in the last conv layer\n",
       "    netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n",
       "    norm (str) -- the name of normalization layers used in the network: batch | instance | none\n",
       "    use_dropout (bool) -- if use dropout layers.\n",
       "    init_type (str)    -- the name of our initialization method.\n",
       "    init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
       "    gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
       "\n",
       "Returns a generator\n",
       "\n",
       "Our current implementation provides two types of generators:\n",
       "    U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
       "    The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
       "\n",
       "    Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n",
       "    Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n",
       "    We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n",
       "\n",
       "The generator has been initialized by <init_net>. It uses RELU for non-linearity."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L127){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### define_G\n",
       "\n",
       ">      define_G (input_nc, output_nc, ngf, netG, norm='batch',\n",
       ">                use_dropout=False, init_type='normal', init_gain=0.02,\n",
       ">                gpu_ids=[])\n",
       "\n",
       "Create a generator\n",
       "\n",
       "Parameters:\n",
       "    input_nc (int) -- the number of channels in input images\n",
       "    output_nc (int) -- the number of channels in output images\n",
       "    ngf (int) -- the number of filters in the last conv layer\n",
       "    netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n",
       "    norm (str) -- the name of normalization layers used in the network: batch | instance | none\n",
       "    use_dropout (bool) -- if use dropout layers.\n",
       "    init_type (str)    -- the name of our initialization method.\n",
       "    init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
       "    gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
       "\n",
       "Returns a generator\n",
       "\n",
       "Our current implementation provides two types of generators:\n",
       "    U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
       "    The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
       "\n",
       "    Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n",
       "    Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n",
       "    We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n",
       "\n",
       "The generator has been initialized by <init_net>. It uses RELU for non-linearity."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(define_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L109){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_net\n",
       "\n",
       ">      init_net (net, init_type='normal', init_gain=0.02, gpu_ids=[])\n",
       "\n",
       "Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
       "Parameters:\n",
       "    net (network)      -- the network to be initialized\n",
       "    init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
       "    gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
       "    gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
       "\n",
       "Return an initialized network."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L109){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_net\n",
       "\n",
       ">      init_net (net, init_type='normal', init_gain=0.02, gpu_ids=[])\n",
       "\n",
       "Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
       "Parameters:\n",
       "    net (network)      -- the network to be initialized\n",
       "    init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
       "    gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
       "    gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
       "\n",
       "Return an initialized network."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(init_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L75){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (net, init_type='normal', init_gain=0.02)\n",
       "\n",
       "Initialize network weights.\n",
       "\n",
       "Parameters:\n",
       "    net (network)   -- network to be initialized\n",
       "    init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
       "    init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
       "\n",
       "We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
       "work better for some applications. Feel free to try yourself."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L75){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (net, init_type='normal', init_gain=0.02)\n",
       "\n",
       "Initialize network weights.\n",
       "\n",
       "Parameters:\n",
       "    net (network)   -- network to be initialized\n",
       "    init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
       "    init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
       "\n",
       "We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
       "work better for some applications. Feel free to try yourself."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_scheduler\n",
       "\n",
       ">      get_scheduler (optimizer, opt)\n",
       "\n",
       "Return a learning rate scheduler\n",
       "\n",
       "Parameters:\n",
       "    optimizer          -- the optimizer of the network\n",
       "    opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions．　\n",
       "                          opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n",
       "\n",
       "For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
       "and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
       "For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n",
       "See https://pytorch.org/docs/stable/optim.html for more details."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_scheduler\n",
       "\n",
       ">      get_scheduler (optimizer, opt)\n",
       "\n",
       "Return a learning rate scheduler\n",
       "\n",
       "Parameters:\n",
       "    optimizer          -- the optimizer of the network\n",
       "    opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions．　\n",
       "                          opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n",
       "\n",
       "For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
       "and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
       "For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n",
       "See https://pytorch.org/docs/stable/optim.html for more details."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(get_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L26){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_norm_layer\n",
       "\n",
       ">      get_norm_layer (norm_type='instance')\n",
       "\n",
       "Return a normalization layer\n",
       "\n",
       "Parameters:\n",
       "    norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
       "\n",
       "For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
       "For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L26){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_norm_layer\n",
       "\n",
       ">      get_norm_layer (norm_type='instance')\n",
       "\n",
       "Return a normalization layer\n",
       "\n",
       "Parameters:\n",
       "    norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
       "\n",
       "For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
       "For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(get_norm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L21){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Identity\n",
       "\n",
       ">      Identity ()\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L21){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Identity\n",
       "\n",
       ">      Identity ()\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Identity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
