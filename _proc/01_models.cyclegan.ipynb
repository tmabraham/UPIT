{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Defines the CycleGAN model architecture.\n",
    "output-file: models.cyclegan.html\n",
    "title: CycleGAN model\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the models that were introduced in the [cycleGAN paper](https://arxiv.org/abs/1703.10593)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### convT_norm_relu\n",
       "\n",
       ">      convT_norm_relu (ch_in:int, ch_out:int,\n",
       ">                       norm_layer:torch.nn.modules.module.Module, ks:int=3,\n",
       ">                       stride:int=2, bias:bool=True)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### convT_norm_relu\n",
       "\n",
       ">      convT_norm_relu (ch_in:int, ch_out:int,\n",
       ">                       norm_layer:torch.nn.modules.module.Module, ks:int=3,\n",
       ">                       stride:int=2, bias:bool=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(convT_norm_relu,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### pad_conv_norm_relu\n",
       "\n",
       ">      pad_conv_norm_relu (ch_in:int, ch_out:int, pad_mode:str,\n",
       ">                          norm_layer:torch.nn.modules.module.Module, ks:int=3,\n",
       ">                          bias:bool=True, pad=1, stride:int=1, activ:bool=True,\n",
       ">                          init=<function kaiming_normal_>, init_gain:int=0.02)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### pad_conv_norm_relu\n",
       "\n",
       ">      pad_conv_norm_relu (ch_in:int, ch_out:int, pad_mode:str,\n",
       ">                          norm_layer:torch.nn.modules.module.Module, ks:int=3,\n",
       ">                          bias:bool=True, pad=1, stride:int=1, activ:bool=True,\n",
       ">                          init=<function kaiming_normal_>, init_gain:int=0.02)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(pad_conv_norm_relu,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L384){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResnetBlock\n",
       "\n",
       ">      ResnetBlock (dim:int, pad_mode:str='reflection',\n",
       ">                   norm_layer:torch.nn.modules.module.Module=None,\n",
       ">                   dropout:float=0.0, bias:bool=True)\n",
       "\n",
       "nn.Module for the ResNet Block"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/junyanz.py#L384){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResnetBlock\n",
       "\n",
       ">      ResnetBlock (dim:int, pad_mode:str='reflection',\n",
       ">                   norm_layer:torch.nn.modules.module.Module=None,\n",
       ">                   dropout:float=0.0, bias:bool=True)\n",
       "\n",
       "nn.Module for the ResNet Block"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(ResnetBlock,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L52){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### resnet_generator\n",
       "\n",
       ">      resnet_generator (ch_in:int, ch_out:int, n_ftrs:int=64,\n",
       ">                        norm_layer:torch.nn.modules.module.Module=None,\n",
       ">                        dropout:float=0.0, n_blocks:int=9,\n",
       ">                        pad_mode:str='reflection')"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L52){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### resnet_generator\n",
       "\n",
       ">      resnet_generator (ch_in:int, ch_out:int, n_ftrs:int=64,\n",
       ">                        norm_layer:torch.nn.modules.module.Module=None,\n",
       ">                        dropout:float=0.0, n_blocks:int=9,\n",
       ">                        pad_mode:str='reflection')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(resnet_generator,title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test for a few things:\n",
    "1. The generator can indeed be initialized correctly\n",
    "2. A random image can be passed into the model successfully with the correct size output\n",
    "3. The CycleGAN generator is equivalent to the [original implementation](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/cycle_gan_model.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a random batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "img1 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = resnet_generator(3,3)\n",
    "with torch.no_grad():\n",
    "    out1 = m(img1)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_junyanz = define_G(3,3,64,'resnet_9blocks', norm='instance')\n",
    "with torch.no_grad():\n",
    "    out2 = m_junyanz(img1)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L68){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### compare_networks\n",
       "\n",
       ">      compare_networks (a, b)\n",
       "\n",
       "A simple function to compare the printed model representations as a proxy for actually comparing two models"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L68){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### compare_networks\n",
       "\n",
       ">      compare_networks (a, b)\n",
       "\n",
       "A simple function to compare the printed model representations as a proxy for actually comparing two models"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(compare_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "test_eq(out1.shape,img1.shape)\n",
    "test_eq(out2.shape,img1.shape)\n",
    "assert compare_networks(list(m_junyanz.children())[0],m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### conv_norm_lr\n",
       "\n",
       ">      conv_norm_lr (ch_in:int, ch_out:int,\n",
       ">                    norm_layer:torch.nn.modules.module.Module=None, ks:int=3,\n",
       ">                    bias:bool=True, pad:int=1, stride:int=1, activ:bool=True,\n",
       ">                    slope:float=0.2, init=<function normal_>,\n",
       ">                    init_gain:int=0.02)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### conv_norm_lr\n",
       "\n",
       ">      conv_norm_lr (ch_in:int, ch_out:int,\n",
       ">                    norm_layer:torch.nn.modules.module.Module=None, ks:int=3,\n",
       ">                    bias:bool=True, pad:int=1, stride:int=1, activ:bool=True,\n",
       ">                    slope:float=0.2, init=<function normal_>,\n",
       ">                    init_gain:int=0.02)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(conv_norm_lr,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L92){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### discriminator\n",
       "\n",
       ">      discriminator (ch_in:int, n_ftrs:int=64, n_layers:int=3,\n",
       ">                     norm_layer:torch.nn.modules.module.Module=None,\n",
       ">                     sigmoid:bool=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L92){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### discriminator\n",
       "\n",
       ">      discriminator (ch_in:int, n_ftrs:int=64, n_layers:int=3,\n",
       ">                     norm_layer:torch.nn.modules.module.Module=None,\n",
       ">                     sigmoid:bool=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(discriminator,title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test discriminator\n",
    "Let's test for similar things:\n",
    "1. The discriminator can indeed be initialized correctly\n",
    "2. A random image can be passed into the discriminator successfully with the correct size output\n",
    "3. The CycleGAN discriminator is equivalent to the [original implementation](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/cycle_gan_model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 30, 30])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = discriminator(3)\n",
    "with torch.no_grad():\n",
    "    out1 = d(img1)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "img1 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 30, 30])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_junyanz = define_D(3,64,'basic',norm='instance')\n",
    "with torch.no_grad():\n",
    "    out2 = d_junyanz(img1)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "test_eq(out1.shape,torch.Size([4, 1, 30, 30]))\n",
    "test_eq(out2.shape,torch.Size([4, 1, 30, 30]))\n",
    "assert compare_networks(list(d_junyanz.children())[0],d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group two discriminators and two generators in a single model, then a `Callback` (defined in `02_cyclegan_training.ipynb`) will take care of training them properly. We use the `PyTorchModelHubMixin` to provide support for pushing to and loading from the [HuggingFace Hub](https://huggingface.co/docs/hub/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L107){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CycleGAN\n",
       "\n",
       ">      CycleGAN (ch_in:int=3, ch_out:int=3, n_features:int=64,\n",
       ">                disc_layers:int=3, gen_blocks:int=9, lsgan:bool=True,\n",
       ">                drop:float=0.0, norm_layer:torch.nn.modules.module.Module=None)\n",
       "\n",
       "CycleGAN model. \n",
       "\n",
       "When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
       "Also outputs identity images after passing the images into generators that outputs its domain type (needed for identity loss).\n",
       "\n",
       "Attributes: \n",
       "\n",
       "`G_A` (`nn.Module`): takes real input B and generates fake input A \n",
       "\n",
       "`G_B` (`nn.Module`): takes real input A and generates fake input B \n",
       "\n",
       "`D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \n",
       "\n",
       "`D_B` (`nn.Module`): trained to make the difference between real input B and fake input B"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L107){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CycleGAN\n",
       "\n",
       ">      CycleGAN (ch_in:int=3, ch_out:int=3, n_features:int=64,\n",
       ">                disc_layers:int=3, gen_blocks:int=9, lsgan:bool=True,\n",
       ">                drop:float=0.0, norm_layer:torch.nn.modules.module.Module=None)\n",
       "\n",
       "CycleGAN model. \n",
       "\n",
       "When called, takes in input batch of real images from both domains and outputs fake images for the opposite domains (with the generators). \n",
       "Also outputs identity images after passing the images into generators that outputs its domain type (needed for identity loss).\n",
       "\n",
       "Attributes: \n",
       "\n",
       "`G_A` (`nn.Module`): takes real input B and generates fake input A \n",
       "\n",
       "`G_B` (`nn.Module`): takes real input A and generates fake input B \n",
       "\n",
       "`D_A` (`nn.Module`): trained to make the difference between real input A and fake input A \n",
       "\n",
       "`D_B` (`nn.Module`): trained to make the difference between real input B and fake input B"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(CycleGAN,title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L119){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CycleGAN.__init__\n",
       "\n",
       ">      CycleGAN.__init__ (ch_in:int=3, ch_out:int=3, n_features:int=64,\n",
       ">                         disc_layers:int=3, gen_blocks:int=9, lsgan:bool=True,\n",
       ">                         drop:float=0.0,\n",
       ">                         norm_layer:torch.nn.modules.module.Module=None)\n",
       "\n",
       "Constructor for CycleGAN model.\n",
       "\n",
       "Arguments: \n",
       "\n",
       "`ch_in` (`int`): Number of input channels (default=3) \n",
       "\n",
       "`ch_out` (`int`): Number of output channels (default=3) \n",
       "\n",
       "`n_features` (`int`): Number of input features (default=64) \n",
       "\n",
       "`disc_layers` (`int`): Number of discriminator layers (default=3) \n",
       "\n",
       "`gen_blocks` (`int`): Number of residual blocks in the generator (default=9) \n",
       "\n",
       "`lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \n",
       "\n",
       "`drop` (`float`): Level of dropout (default=0) \n",
       "\n",
       "`norm_layer` (`nn.Module`): Type of normalization layer to use in the models (default=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L119){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CycleGAN.__init__\n",
       "\n",
       ">      CycleGAN.__init__ (ch_in:int=3, ch_out:int=3, n_features:int=64,\n",
       ">                         disc_layers:int=3, gen_blocks:int=9, lsgan:bool=True,\n",
       ">                         drop:float=0.0,\n",
       ">                         norm_layer:torch.nn.modules.module.Module=None)\n",
       "\n",
       "Constructor for CycleGAN model.\n",
       "\n",
       "Arguments: \n",
       "\n",
       "`ch_in` (`int`): Number of input channels (default=3) \n",
       "\n",
       "`ch_out` (`int`): Number of output channels (default=3) \n",
       "\n",
       "`n_features` (`int`): Number of input features (default=64) \n",
       "\n",
       "`disc_layers` (`int`): Number of discriminator layers (default=3) \n",
       "\n",
       "`gen_blocks` (`int`): Number of residual blocks in the generator (default=9) \n",
       "\n",
       "`lsgan` (`bool`): LSGAN training objective (output unnormalized float) or not? (default=True) \n",
       "\n",
       "`drop` (`float`): Level of dropout (default=0) \n",
       "\n",
       "`norm_layer` (`nn.Module`): Type of normalization layer to use in the models (default=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(CycleGAN.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L146){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CycleGAN.forward\n",
       "\n",
       ">      CycleGAN.forward (input)\n",
       "\n",
       "Forward function for CycleGAN model. The input is a tuple of a batch of real images from both domains A and B."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/tmabraham/UPIT/tree/master/blob/master/upit/models/cyclegan.py#L146){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CycleGAN.forward\n",
       "\n",
       ">      CycleGAN.forward (input)\n",
       "\n",
       "Forward function for CycleGAN model. The input is a tuple of a batch of real images from both domains A and B."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(CycleGAN.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ModelHubMixin.push_to_hub\n",
       "\n",
       ">      ModelHubMixin.push_to_hub (repo_path_or_name:Optional[str]=None,\n",
       ">                                 repo_url:Optional[str]=None,\n",
       ">                                 commit_message:Optional[str]='Add model',\n",
       ">                                 organization:Optional[str]=None,\n",
       ">                                 private:Optional[bool]=None,\n",
       ">                                 api_endpoint:Optional[str]=None,\n",
       ">                                 use_auth_token:Union[bool,str,NoneType]=None,\n",
       ">                                 git_user:Optional[str]=None,\n",
       ">                                 git_email:Optional[str]=None,\n",
       ">                                 config:Optional[dict]=None)\n",
       "\n",
       "Upload model checkpoint or tokenizer files to the Hub while\n",
       "synchronizing a local clone of the repo in `repo_path_or_name`.\n",
       "\n",
       "Parameters:\n",
       "    repo_path_or_name (`str`, *optional*):\n",
       "        Can either be a repository name for your model or tokenizer in\n",
       "        the Hub or a path to a local folder (in which case the\n",
       "        repository will have the name of that local folder). If not\n",
       "        specified, will default to the name given by `repo_url` and a\n",
       "        local directory with that name will be created.\n",
       "    repo_url (`str`, *optional*):\n",
       "        Specify this in case you want to push to an existing repository\n",
       "        in the hub. If unspecified, a new repository will be created in\n",
       "        your namespace (unless you specify an `organization`) with\n",
       "        `repo_name`.\n",
       "    commit_message (`str`, *optional*):\n",
       "        Message to commit while pushing. Will default to `\"add config\"`,\n",
       "        `\"add tokenizer\"` or `\"add model\"` depending on the type of the\n",
       "        class.\n",
       "    organization (`str`, *optional*):\n",
       "        Organization in which you want to push your model or tokenizer\n",
       "        (you must be a member of this organization).\n",
       "    private (`bool`, *optional*):\n",
       "        Whether the repository created should be private.\n",
       "    api_endpoint (`str`, *optional*):\n",
       "        The API endpoint to use when pushing the model to the hub.\n",
       "    use_auth_token (`bool` or `str`, *optional*):\n",
       "        The token to use as HTTP bearer authorization for remote files.\n",
       "        If `True`, will use the token generated when running\n",
       "        `transformers-cli login` (stored in `~/.huggingface`). Will\n",
       "        default to `True` if `repo_url` is not specified.\n",
       "    git_user (`str`, *optional*):\n",
       "        will override the `git config user.name` for committing and\n",
       "        pushing files to the hub.\n",
       "    git_email (`str`, *optional*):\n",
       "        will override the `git config user.email` for committing and\n",
       "        pushing files to the hub.\n",
       "    config (`dict`, *optional*):\n",
       "        Configuration object to be saved alongside the model weights.\n",
       "\n",
       "Returns:\n",
       "    The url of the commit of your model in the given repository."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ModelHubMixin.push_to_hub\n",
       "\n",
       ">      ModelHubMixin.push_to_hub (repo_path_or_name:Optional[str]=None,\n",
       ">                                 repo_url:Optional[str]=None,\n",
       ">                                 commit_message:Optional[str]='Add model',\n",
       ">                                 organization:Optional[str]=None,\n",
       ">                                 private:Optional[bool]=None,\n",
       ">                                 api_endpoint:Optional[str]=None,\n",
       ">                                 use_auth_token:Union[bool,str,NoneType]=None,\n",
       ">                                 git_user:Optional[str]=None,\n",
       ">                                 git_email:Optional[str]=None,\n",
       ">                                 config:Optional[dict]=None)\n",
       "\n",
       "Upload model checkpoint or tokenizer files to the Hub while\n",
       "synchronizing a local clone of the repo in `repo_path_or_name`.\n",
       "\n",
       "Parameters:\n",
       "    repo_path_or_name (`str`, *optional*):\n",
       "        Can either be a repository name for your model or tokenizer in\n",
       "        the Hub or a path to a local folder (in which case the\n",
       "        repository will have the name of that local folder). If not\n",
       "        specified, will default to the name given by `repo_url` and a\n",
       "        local directory with that name will be created.\n",
       "    repo_url (`str`, *optional*):\n",
       "        Specify this in case you want to push to an existing repository\n",
       "        in the hub. If unspecified, a new repository will be created in\n",
       "        your namespace (unless you specify an `organization`) with\n",
       "        `repo_name`.\n",
       "    commit_message (`str`, *optional*):\n",
       "        Message to commit while pushing. Will default to `\"add config\"`,\n",
       "        `\"add tokenizer\"` or `\"add model\"` depending on the type of the\n",
       "        class.\n",
       "    organization (`str`, *optional*):\n",
       "        Organization in which you want to push your model or tokenizer\n",
       "        (you must be a member of this organization).\n",
       "    private (`bool`, *optional*):\n",
       "        Whether the repository created should be private.\n",
       "    api_endpoint (`str`, *optional*):\n",
       "        The API endpoint to use when pushing the model to the hub.\n",
       "    use_auth_token (`bool` or `str`, *optional*):\n",
       "        The token to use as HTTP bearer authorization for remote files.\n",
       "        If `True`, will use the token generated when running\n",
       "        `transformers-cli login` (stored in `~/.huggingface`). Will\n",
       "        default to `True` if `repo_url` is not specified.\n",
       "    git_user (`str`, *optional*):\n",
       "        will override the `git config user.name` for committing and\n",
       "        pushing files to the hub.\n",
       "    git_email (`str`, *optional*):\n",
       "        will override the `git config user.email` for committing and\n",
       "        pushing files to the hub.\n",
       "    config (`dict`, *optional*):\n",
       "        Configuration object to be saved alongside the model weights.\n",
       "\n",
       "Returns:\n",
       "    The url of the commit of your model in the given repository."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(CycleGAN.push_to_hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ModelHubMixin.from_pretrained\n",
       "\n",
       ">      ModelHubMixin.from_pretrained (pretrained_model_name_or_path:str,\n",
       ">                                     force_download:bool=False,\n",
       ">                                     resume_download:bool=False,\n",
       ">                                     proxies:Dict=None,\n",
       ">                                     use_auth_token:Optional[str]=None,\n",
       ">                                     cache_dir:Optional[str]=None,\n",
       ">                                     local_files_only:bool=False,\n",
       ">                                     **model_kwargs)\n",
       "\n",
       "Instantiate a pretrained PyTorch model from a pre-trained model\n",
       "        configuration from huggingface-hub. The model is set in\n",
       "        evaluation mode by default using `model.eval()` (Dropout modules\n",
       "        are deactivated). To train the model, you should first set it\n",
       "        back in training mode with `model.train()`.\n",
       "\n",
       "Parameters:\n",
       "    pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
       "        Can be either:\n",
       "            - A string, the `model id` of a pretrained model\n",
       "              hosted inside a model repo on huggingface.co.\n",
       "              Valid model ids can be located at the root-level,\n",
       "              like `bert-base-uncased`, or namespaced under a\n",
       "              user or organization name, like\n",
       "              `dbmdz/bert-base-german-cased`.\n",
       "            - You can add `revision` by appending `@` at the end\n",
       "              of model_id simply like this:\n",
       "              `dbmdz/bert-base-german-cased@main` Revision is\n",
       "              the specific model version to use. It can be a\n",
       "              branch name, a tag name, or a commit id, since we\n",
       "              use a git-based system for storing models and\n",
       "              other artifacts on huggingface.co, so `revision`\n",
       "              can be any identifier allowed by git.\n",
       "            - A path to a `directory` containing model weights\n",
       "              saved using\n",
       "              [`~transformers.PreTrainedModel.save_pretrained`],\n",
       "              e.g., `./my_model_directory/`.\n",
       "            - `None` if you are both providing the configuration\n",
       "              and state dictionary (resp. with keyword arguments\n",
       "              `config` and `state_dict`).\n",
       "    force_download (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to force the (re-)download of the model weights\n",
       "        and configuration files, overriding the cached versions\n",
       "        if they exist.\n",
       "    resume_download (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to delete incompletely received files. Will\n",
       "        attempt to resume the download if such a file exists.\n",
       "    proxies (`Dict[str, str]`, *optional*):\n",
       "        A dictionary of proxy servers to use by protocol or\n",
       "        endpoint, e.g., `{'http': 'foo.bar:3128',\n",
       "        'http://hostname': 'foo.bar:4012'}`. The proxies are\n",
       "        used on each request.\n",
       "    use_auth_token (`str` or `bool`, *optional*):\n",
       "        The token to use as HTTP bearer authorization for remote\n",
       "        files. If `True`, will use the token generated when\n",
       "        running `transformers-cli login` (stored in\n",
       "        `~/.huggingface`).\n",
       "    cache_dir (`Union[str, os.PathLike]`, *optional*):\n",
       "        Path to a directory in which a downloaded pretrained\n",
       "        model configuration should be cached if the standard\n",
       "        cache should not be used.\n",
       "    local_files_only(`bool`, *optional*, defaults to `False`):\n",
       "        Whether to only look at local files (i.e., do not try to\n",
       "        download the model).\n",
       "    model_kwargs (`Dict`, *optional*):\n",
       "        model_kwargs will be passed to the model during\n",
       "        initialization\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Passing `use_auth_token=True` is required when you want to use a\n",
       "private model.\n",
       "\n",
       "</Tip>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ModelHubMixin.from_pretrained\n",
       "\n",
       ">      ModelHubMixin.from_pretrained (pretrained_model_name_or_path:str,\n",
       ">                                     force_download:bool=False,\n",
       ">                                     resume_download:bool=False,\n",
       ">                                     proxies:Dict=None,\n",
       ">                                     use_auth_token:Optional[str]=None,\n",
       ">                                     cache_dir:Optional[str]=None,\n",
       ">                                     local_files_only:bool=False,\n",
       ">                                     **model_kwargs)\n",
       "\n",
       "Instantiate a pretrained PyTorch model from a pre-trained model\n",
       "        configuration from huggingface-hub. The model is set in\n",
       "        evaluation mode by default using `model.eval()` (Dropout modules\n",
       "        are deactivated). To train the model, you should first set it\n",
       "        back in training mode with `model.train()`.\n",
       "\n",
       "Parameters:\n",
       "    pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
       "        Can be either:\n",
       "            - A string, the `model id` of a pretrained model\n",
       "              hosted inside a model repo on huggingface.co.\n",
       "              Valid model ids can be located at the root-level,\n",
       "              like `bert-base-uncased`, or namespaced under a\n",
       "              user or organization name, like\n",
       "              `dbmdz/bert-base-german-cased`.\n",
       "            - You can add `revision` by appending `@` at the end\n",
       "              of model_id simply like this:\n",
       "              `dbmdz/bert-base-german-cased@main` Revision is\n",
       "              the specific model version to use. It can be a\n",
       "              branch name, a tag name, or a commit id, since we\n",
       "              use a git-based system for storing models and\n",
       "              other artifacts on huggingface.co, so `revision`\n",
       "              can be any identifier allowed by git.\n",
       "            - A path to a `directory` containing model weights\n",
       "              saved using\n",
       "              [`~transformers.PreTrainedModel.save_pretrained`],\n",
       "              e.g., `./my_model_directory/`.\n",
       "            - `None` if you are both providing the configuration\n",
       "              and state dictionary (resp. with keyword arguments\n",
       "              `config` and `state_dict`).\n",
       "    force_download (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to force the (re-)download of the model weights\n",
       "        and configuration files, overriding the cached versions\n",
       "        if they exist.\n",
       "    resume_download (`bool`, *optional*, defaults to `False`):\n",
       "        Whether to delete incompletely received files. Will\n",
       "        attempt to resume the download if such a file exists.\n",
       "    proxies (`Dict[str, str]`, *optional*):\n",
       "        A dictionary of proxy servers to use by protocol or\n",
       "        endpoint, e.g., `{'http': 'foo.bar:3128',\n",
       "        'http://hostname': 'foo.bar:4012'}`. The proxies are\n",
       "        used on each request.\n",
       "    use_auth_token (`str` or `bool`, *optional*):\n",
       "        The token to use as HTTP bearer authorization for remote\n",
       "        files. If `True`, will use the token generated when\n",
       "        running `transformers-cli login` (stored in\n",
       "        `~/.huggingface`).\n",
       "    cache_dir (`Union[str, os.PathLike]`, *optional*):\n",
       "        Path to a directory in which a downloaded pretrained\n",
       "        model configuration should be cached if the standard\n",
       "        cache should not be used.\n",
       "    local_files_only(`bool`, *optional*, defaults to `False`):\n",
       "        Whether to only look at local files (i.e., do not try to\n",
       "        download the model).\n",
       "    model_kwargs (`Dict`, *optional*):\n",
       "        model_kwargs will be passed to the model during\n",
       "        initialization\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Passing `use_auth_token=True` is required when you want to use a\n",
       "private model.\n",
       "\n",
       "</Tip>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(CycleGAN.from_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model tests\n",
    "\n",
    "Again, let's check that the model can be called sucsessfully and outputs the correct shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "cyclegan_model = CycleGAN()\n",
    "img1 = torch.randn(4,3,256,256)\n",
    "img2 = torch.randn(4,3,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 6.67 s, total: 1min 22s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): cyclegan_output = cyclegan_model((img1,img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(len(cyclegan_output),4)\n",
    "for output_batch in cyclegan_output:\n",
    "    test_eq(output_batch.shape,img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/tmabraham/upit-cyclegan-test into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95a20b273084e1a8d9ea94b3cdb7f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 3.34k/108M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/tmabraham/upit-cyclegan-test\n",
      "   a41e9e0..2331f7d  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/tmabraham/upit-cyclegan-test/commit/2331f7d345d719ac1fdfb10b2cddf58abd7931bb'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "cyclegan_model.push_to_hub('upit-cyclegan-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in HuggingFace Hub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CycleGAN(\n",
       "  (D_A): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (D_B): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (G_A): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (18): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       "  (G_B): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (18): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "#| output: false\n",
    "cyclegan_model.from_pretrained('tmabraham/upit-cyclegan-test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
